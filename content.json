[{"title":"Java诊断工具-Arthas简单使用","date":"2019-12-31T01:31:00.000Z","path":"tool/arthas.html","text":"Arthas 是阿里中间件基于 Greys 进⾏⼆次开发开源的一个监控线上应用内存、线程、gc情况的诊断产品，能在不修改服务代码的情况下，对我们产生的业务问题进行诊断，例如查看方法的入参、出参、异常或方法调用链的耗时等，能够很好的提升线上问题排查效率。 Arthas 官方文档地址：https://alibaba.github.io/arthas/index.html 在官方文档中已经提到，Arthas 能为你做什么？ 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ 安装下载arthas-boot.jar，之后使用java -jar启动即可： 12wget https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar 启动后选择对应java应用进程即可 命令dashboard显示当前系统的实时数据面板，可以按 ctrl+c 退出。 使用参考 数据说明 ID: Java线程ID，注意这个ID并不能跟jstack中的nativeID对应 NAME: 线程名称 GROUP: 线程组名称 PRIORITY: 线程优先级, 范围为1~10，越大优先级越高 STATE: 线程状态 CPU%: 线程消耗的cpu占比，采样100ms，将所有线程在这100ms内的cpu使用量求和，再算出每个线程的cpu使用占比。 TIME: 线程运行总时间，数据格式为分：秒 INTERRUPTED: 线程当前的中断位状态 DAEMON: 是否是daemon线程 thread查看当前线程信息及堆栈信息 参数说明 参数名称 参数说明 使用范例 id 线程id thread 1 n 指定最忙的前N个线程并打印堆栈 thread -n 5 b 找出当前阻塞其他线程的线程 thread -b i 指定cpu占比统计的采样间隔，单位为毫秒 thread -n 5 -i 1000 thread 查看所有线程信息 arthas-thread thread -n 5 查看当前最忙的前N个线程并打印堆栈信息 arthas-thread-n 这里的cpu统计的是一段采样间隔内，当前JVM里各个线程所占用的cpu时间占总cpu时间的百分比。 其计算方法为： 首先进行一次采样，调用的是java.lang.management.ThreadMXBean#getThreadCpuTime这个接口，获得所有线程的cpu的使用时间，然后睡眠一段时间，默认100ms，可以通过-i参数指定，然后再采样一次，最后得出这段时间内各个线程消耗的cpu时间情况，最后算出百分比。 因为这个统计也会产生一定的开销，因此会看到as的线程占用一定的百分比，为了降低统计自身的开销带来的影响，可以把采样间隔拉长一些，比如5000毫秒。 jad将JVM中实际运行的class反编译指定已加载类的java源码 参数说明 参数名称 参数说明 使用范例 class-pattern 类名匹配 jad java.lang.String c 指定类加载器中的类进行编译 jad org.slf4j.Logger -c 55f96302 指定需要反编译的类1jad java.lang.String arthas-jad 反编译时只显示源码1jad --source-only java.lang.String arthas-jad-only 反编译时指定方法1jad java.lang.String equals arthas-jad-method 反编译时指定类加载器12jad org.slf4j.Loggerjad org.slf4j.Logger -c 55f96302 当有多个类加载器加载了所指定的类时，jad 命令会输出对应不同类加载器中实例的 hashcode，此时重新执行 jad 命令并使用 -c 参数指定 hashcode 即可指定加载类加载器中的类 arthas-jad-c watchwatch 命令可以观察方法的返回值、入参、出参及方法抛出异常。 参数说明 参数名称 参数说明 b 在方法调用之前观察 e 在方法异常之后观察 s 在方法返回之后观察 f 在方法结束之后(正常返回和异常返回)观察 x 指定输出结果的属性遍历深度，默认为 1 watch 命令示例 ： watch demo.MathGame primeFactors “{params,returnObj}” -x 2 watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后 4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出 条件表达式1watch demo.MathGame primeFactors \"&#123;params[0],target&#125;\" \"params[0]&lt;0 限定条件为第一个参数小于0的值 观察方法异常信息1watch demo.MathGame primeFactors \"&#123;params[0],throwExp&#125;\" -e -x 2 -x 表示遍历深度，通过调整该参数来打印具体结果，默认值为1 -e 表示抛出异常时 根据方法耗时进行过滤1watch demo.MathGame primeFactors '&#123;params, returnObj&#125;' '#cost&gt;200' -x 2 #cost 的单位为 ms，只输出方法耗时大于200ms的方法调用 观察当前对象中的属性1watch demo.MathGame primeFactors 'target.illegalArgumentCount' 使用target来表示当前对象，使用target.fieldName来访问对象中的某属性 trace方法内部调用路径，并输出方法路径上的每个节点上耗时 1trace demo.MathGame run -n 1 '#cost &gt; 10' -n 指定方法捕捉结果次数 #cost 可以指定方法的执行耗时大于某个指定的时间后的结果 其他命令 jvm——查看当前JVM信息 sc——查看JVM已加载的类信息 sm——查看已加载类的方法信息 dump——dump 已加载类的 bytecode 到特定目录 headdump——dump java heap, 类似jmap命令heap dump功能 classloader——查看classloader的继承树，urls，类加载信息 monitor——方法执行监控 1monitor -c 5 demo.MathGame primeFactors stack——输出当前方法被调用的调用路径 1stack demo.MathGame primeFactors 'params[0]&lt;0' '#cost&gt;5' 基础命令 help——查看命令帮助信息 cls——清空当前屏幕区域 session——查看当前会话的信息 reset——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类 version——输出当前目标 Java 进程所加载的 Arthas 版本号 history——打印命令历史 quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响 stop——和shutdown命令一致（推荐使用，避免误操作） shutdown——关闭 Arthas 服务端，所有 Arthas 客户端全部退出 keymap——Arthas快捷键列表及自定义快捷键","tags":[{"name":"工具","slug":"工具","permalink":"https://jinjinz.top/tags/工具/"}]},{"title":"深入理解Redis的基础数据结构","date":"2019-10-24T09:10:06.000Z","path":"redis/redis-base.html","text":"前言 Redis是一个K/V类型的数据库，Key的类型就是字符串，而Value可以支持不同类型，不仅限于简单的字符串，以下将分别介绍五种简单的数据类型中的数据结构： 二进制安全的字符串 列表，基于插入顺序进行排序的元素列表，一般会基于链表实现 哈希，每个字段关联一个value，字段和value都是string类型 集合，保存没有重复值的元素集合，元素中没有顺序 有序集合，与集合类似，但每个元素都与一个 score 的值关联，元素总是按照score字段来进行排序，因此可以获取最大的10个元素或是最小的10个元素等等操作。 字符串Redis中的每个键值对，其实就是一个 dictEntry 结构，其中保存了key和value的指针，代码如下： 12345678typedef struct dictEntry &#123; void *key; /* key */ union &#123; void *val; uint64_t u64; /* value */ int64_t s64; double d; &#125; v; struct dictEntry *next; &#125; dictEntry; key的类型就是字符串，其指向的是Redis自定义的SDS类型，Redis基于C语言的字符数组简单实现了一个字符串的类型。 而value的类型并不会直接指向SDS或是其他具体类型，而是一个 redisObject 类型，在这五种常用类型中，都是通过 redisObject 来存储的。 redisObject 的定义代码如下： 1234567typedef struct redisObject &#123; unsigned type:4; /* 对象的类型，例如：OBJ_STRING、OBJ_LIST、OBJ_HASH、OBJ_SET、OBJ_ZSET */ unsigned encoding:4; /* 数据结构内部编码 */ unsigned lru:LRU_BITS; /* 与内存回收相关 */ int refcount; /* 引用计数。*/ void *ptr; /* 指向对象实际的数据结构 */&#125; robj; 字符串的内部编码有三种： int，存储8个字节的整数值 embstr，存储小于44个字节的字符串 raw，存储大于44字节的字符串 当使用 embstr 编码时，只需一次内存分配函数来分配一个连续的内存空间，在这个连续的内存空间中同时包含了 redisObject 和 SDS 两个结构，而 raw 编码需要两次内存分配来分别创建。同理，在释放内存空间时，embstr 仅需要释放一次，而 raw 编码需要调用两次释放函数。 但是对于 embstr 编码的字符串对象来讲，只要这个字符串被修改了，字符串对象就会将编码转为 raw ，也就是说，embstr 编码的字符串对象实际上是只读的。 而对于 int 编码的字符串对象，如果字符串对象被修改后不再是整数值，则编码同样会转为 raw 的字符串对象。 SDSRedis没有使用C语言的字符数组作为字符串的实现，而是自定义了简单动态字符串(simple dynamic string)，简称为SDS，Redis使用SDS作为字符串的实现。 在C语言中，如果使用字符数组实现长度为N的字符串，就需要使用长度N+1的字符数组来表示，且字符数组的最后一个元素必须是空字符 \\0 。 而Redis的SDS结构还是遵循C语言字符串中以空字符 \\0 结尾的惯例，但这一字节的空间不会被计算到使用字符串的长度中，SDS的结构如下： 12345struct sdshdr &#123; int len; /* 记录 buf 数组中已使用字节的数量,也就是字符串的长度 */ int free; /* 记录 buf 数组中未使用字节的数量 */ char buf[]; /* 保存字符串的字节数组 */&#125;; 使用SDS存储字符串的好处有以下几点： 字符串长度可以直接获取 在字符数组中，无法记录字符串的长度信息，所以获取字符串的长度需要遍历整个字符数组进行计数，直到遇到空字符串结尾为止，而SDS结构中的len属性记录了长度信息，字符串长度可以直接进行获取。 不会造成缓冲区溢出 字符数组的另一个问题则是，如果没有为该字符数组分配足够的空间，直接在数组末尾拼接字符串的话，可能会造成缓冲区溢出的错误。而SDS的空间分配策略会对分配空间进行检查，如果空间不足则会直接进行扩展。 二进制安全 字符数组以空字符串结尾，这导致了C语言字符串不能直接保存音频数据，否则第一个被读到的空字符串就将直接被认为是字符串的结尾。而SDS的API都会以处理二进制的方式来处理字符数组中的数据。 减少内存重分配 字符数组的空间总是预先分配好的，每次对字符串的增加或减少，都会对这个数组的空间大小进行一次扩展或是释放的操作。在SDS中，字符数组可以预先分配空间，由len字段记录已经使用的空间，由free字段记录未使用的空间。SDS由此实现了空间预分配和惰性空间释放的策略。 空间预分配 对SDS进行修改时，如果需要进行空间扩展，除了分配所需的空间，还会对SDS分配额外不使用的空间，由此策略减少了对字符串进行连续增长操作时所需的内存重分配次数。 惰性空间释放 当SDS需要缩短字符串长度时，程序不会立刻将这些内存进行回收，而是使用free字段将字节数量记录以便后续使用，且SDS的API也可以直接释放该属性中的未使用空间。 SDS与字符数组对比 C 字符串 SDS 获取字符串长度的复杂度为 O(N) 。 获取字符串长度的复杂度为 O(1) 。 API 是不安全的，可能会造成缓冲区溢出。 API 是安全的，不会造成缓冲区溢出。 修改字符串长度N次必然需要执行N次内存重分配。 修改字符串长度N次最多需要执行N次内存重分配。 只能保存文本数据。 可以保存文本或者二进制数据。 可以使用所有 &lt;string.h&gt; 库中的函数。 可以使用一部分 &lt;string.h&gt; 库中的函数。 列表列表类型存储了一个有序的字符串列表，可以用来充当队列或是栈，关于列表的操作命令可以查看Redis命令参考。 Redis 中的列表使用 quicklist 结构来存储， quicklist 存储了一个双向链表，其中的每个节点结构是 ziplist。 quicklist 的结构如下： 12345678typedef struct quicklist &#123; quicklistNode *head; /* 链表头指针 */ quicklistNode *tail; /* 链表尾指针 */ unsigned long count; /* 所有的 ziplist 存储的元素数量 */ unsigned long len; /* 节点数量,也就是链表的长度 */ int fill : 16; unsigned int compress : 16; &#125; quicklist; quicklistNode 的结构如下： 123456789101112typedef struct quicklistNode &#123; struct quicklistNode *prev; /* 上一个节点 */ struct quicklistNode *next; /* 下一个节点 */ unsigned char *zl; /* 指向 ziplist */ unsigned int sz; /* ziplist 占用了多少字节 */ unsigned int count : 16; unsigned int encoding : 2; unsigned int container : 2; unsigned int recompress : 1; unsigned int attempted_compress : 1; unsigned int extra : 10;&#125; quicklistNode; quicklistNode 中实际存储的数据是指向了一个 ziplist 结构，列表的存储结构如下图所示： ziplist ziplist.c 的文件头部注释中，对ziplist的做出如下解释： The ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. ziplist 是一个双向链表 ，但 ziplist 为了提高存储效率，是存储在连续的内存空间中的；并且对于值的存储，不同长度的值需要存储的字节数也不同，也就是说，对于大一些的值，就多用一些字节来存储，而对于小一些的值，则就可以少用一些字节来存储；ziplist 中的每个节点通过存储上一个节点的长度和当前节点的长度来实现这种功能。 一个 ziplist 可以包含任意数量的节点 (entry)，每个节点都可以保存一个字节数组或整数值。ziplist 的各个组成部分如下： 1&lt;zlbytes&gt; &lt;zltail&gt; &lt;zllen&gt; &lt;entry&gt; &lt;entry&gt; ... &lt;entry&gt; &lt;zlend&gt; 属性 说明 zlbytes 记录 ziplist 总使用的内存字节数。 zltail 记录 ziplist 表尾节点距离 ziplist 的起始地址有多少字节，这使得不需要遍历整个 ziplist 就可以确定表尾节点的地址。 zllen 记录 ziplist 的节点数量， 当这个值等于 UINT16_MAX (65535) 时， 节点的真实数量需要遍历整个ziplist 才能得出。 entry ziplist 的节点，节点的长度由节点保存的内容决定。 zlend 特殊值 0xFF（十进制 255 ），用于标记 ziplist 的末端。 哈希哈希类型存储了无序的散列表，每个字段可以有一个对应的值，但其值只能是字符串类型，存储内容如下： 哈希可以使用两种数据结构来实现，分别是 ziplist 和 hashtable。 ziplistziplist 在上面存储列表类型时已经有所介绍，但 ziplist 也可以用来作为哈希类型的实现，当有新的键值对加入哈希对象中时，先将键的 ziplist 节点推入到 ziplist 的表尾，然后再将值的 ziplist 节点推入到 ziplist 表尾。 也就是说同一个键值对的两个 ziplist 节点肯定是紧挨在一起的两个节点，键节点在前，值节点在后；且键值对会按照添加顺序依次排在上一个键值对的后面。 只有当哈希对象满足以下两个条件时，哈希对象才会使用 ziplist 编码： 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节； 哈希对象保存的键值对数量小于512 个； 不满足这两个条件时，哈希对象使用 hashtable 编码存储，这两个条件的上限可以通过 redis 的配置文件更改。 hashtablehashtable 是作为字典保存键值对的数据结构；在字典中，每一个键都可以和一个值进行关联，这些关联的键和值就被成为键值对。 字典中的每个键都是不允许重复的，我们可以根据键来查找与之对应的值进行更新或删除等相关操作。 哈希表的结构如下： 123456typedef struct dictht &#123; dictEntry **table; /* 哈希表数组 */ unsigned long size; /* 哈希表大小 */ unsigned long sizemask; /* 掩码大小，用于计算索引值。总是等于 size-1 */ unsigned long used; /* 已有节点数量 */&#125; dictht; 哈希表节点 dictEntry 结构如下： 12345678910typedef struct dictEntry &#123; void *key; /* 键 */ union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; /* 值 */ struct dictEntry *next; /* 指向下一个节点 */ &#125; dictEntry; 当发生哈希键冲突时，多个键值对会形成链表，新节点会被添加到表头，然后将 next 指针指向原表头。 字典结构如下： 123456typedef struct dict &#123; dictType *type; /* 类型 */ void *privdata; /* 私有数据 */ dictht ht[2]; /* 哈希表 */ long rehashidx; /* rehash 索引,rehash 不在进行时，值为 -1 */ &#125; dict; 在字典结构中，ht 属性是一个长度为2的数组，其包含了两个哈希表，一般情况下字典只会使用 ht[0] 作为哈希表使用，而 ht[1] 的哈希表只会在对 ht[0] 的哈希表进行 rehash 时使用。 rehashidx 属性记录了 rehash 的进度， 如果当前没有进行 rehash ， 那么它的值为 -1 。 也就是说，字典的总体结构如下图所示： rehash随着哈希表中保存的键值对逐渐的增多或减少，为了让哈希表的负载因子维持在一个合理的范围内，需要对哈希表进行扩展或收缩；这个过程通过 rehash 完成，rehash的大致步骤如下： 为字典的 ht[1] 上的哈希表分配空间，空间的大小是2的n次方 。 将 ht[0] 中的所有键值对 rehash 到 ht[1] 上， rehash 指重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 上的哈希表指定位置上。 当 ht[0] 的所有键值对迁移到 ht[1] 之后，释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表。 rehash 是分多次进行的，这是为了避免对服务器的性能造成过大的影响，所以 rehash 的详细步骤如下： 为字典的 ht[1] 上的哈希表分配空间，空间的大小是2的n次方；此时字典还是持有 ht[0] 上的哈希表 。 将索引计数器变量 rehashidx 的值设置为 0 ，表示 rehash 工作开始。 在 rehash 期间， 每次对字典执行增删改查操作时， 会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 将 rehashidx 属性的值加一。 随着字典操作的不断执行，ht[0] 上的所有键值对都会被 rehash 至 ht[1] ，最终将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作完成。 这种操作将 rehash 所需要的计算工作量分摊到了每次对字典的增删改查操作中，避免了集中式 rehash 带来的庞大计算量从而影响服务器的性能；在 rehash 过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表，新添加的键值对只会被保存到 ht[1] 中，查找键的过程则会同时查找两个哈希表。 集合集合类型中的元素为 String 类型的字符串，且在集合中不包含重复项；当集合中的元素类型都是整数时，集合类型使用 intset 编码的整数集合来存储元素，否则使用 hashtable 编码的字典来存储元素。 hashtable使用字典类型来存储集合元素时，字典中的每个键都是一个集合元素，而字典的值被设置为NULL。 当集合对象满足以下两个条件时，集合对象会使用 intset 编码： 集合对象中保存的所有元素都是整数值； 集合对象中保存的元素数量没有超过 512 个； 没有满足这两个条件的集合对象则使用 hashtable 编码，并且在使用 intset 编码时，有任意一个条件不能满足时，则会执行对象的编码转换操作，将 intset 编码转换为 hashtable 编码 。这两个条件的上限可以通过配置文件更改。 intset整数集合作为集合中只保存了整数且元素数量不多时的实现，结构如下： 12345typedef struct intset &#123; uint32_t encoding; /* 编码方式 */ uint32_t length; /* 元素数量 */ int8_t contents[]; /* 元素数组 */ &#125; intset; 整数集合的元素实际就存储在了 contents 数组中。 有序集合有序的集合对象，集合中的元素都有 score 属性作为排序依据，有序集合的编码为 ziplist 或skiplist。 ziplist使用 ziplist 作为有序集合的实现时，每个集合元素使用两个紧挨的 ziplist 节点保存，第一个节点保存元素信息，第二个节点则保存元素的 score。 在 ziplist 中，根据元素的 score 进行排序，score 越小的节点，则越靠近表头，当有更小的节点插入时，需要移动节点。 只有当有序集合对象满足以下两个条件时，有序集合对象才会使用 ziplist 编码： 有序集合保存的所有元素的长度都小于 64 字节； 有序集合对象保存的元素数量小于 128 个； 不满足这两个条件时，哈希对象使用 skiplist 编码存储，这两个条件的上限可以通过配置文件更改。 skiplistskiplist 编码的有序集合对象使用 zset 结构作为底层实现， 一个 zset 结构同时包含一个字典和一个跳跃表： 1234typedef struct zset &#123; zskiplist *zsl; /* 跳跃表 */ dict *dict; /* 字典 */ &#125; zset; 跳跃表是一种支持平均 O(log N) 最坏 O(N) 复杂度的节点查找的有序数据结构，且在大部分情况下跳跃表的性能可以和平衡树相比较。 在 redis 中，跳跃表的结构由 zskiplistNode 和 zskiplist 组成，其组成如下图： zskiplist 的结构如下： 12345typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; /* 表头和表尾节点 */ unsigned long length; /* 节点数量 */ int level; /* 最大层数 */&#125; zskiplist; zskiplistNode 的结构如下： 12345678910typedef struct zskiplistNode &#123; struct zskiplistNode *backward; /* 后退指针 */ double score; /* 分值 */ robj *obj; /* 元素 */ struct zskiplistLevel &#123; struct zskiplistNode *forward; /* 前进指针*/ unsigned int span; /* 跨越的节点数 */ &#125; level[]; /* 层 */&#125; zskiplistNode; 除了跳跃表，zset 中的字典结构还保存了每个元素对应 score 的映射；通过字典，在查找元素对应的 score 时就可以直接从字典中返回，虽然元素同时在跳跃表和字典中同时保存，但这两种数据结构通过指针共享了相同元素的对象，因此并不会浪费额外的内存。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://jinjinz.top/tags/Redis/"}]},{"title":"并发编程的最佳实践","date":"2019-09-04T02:55:30.000Z","path":"concurrent/optimal.html","text":"前言 并发编程是目的其实就是为了提高我们程序的性能，但是在日常的工作过程中，大部分开发人员可能没有机会去接触并发编程，而在并发编程中忽略的一些细节可能就会引发问题的产生，以下仅介绍我个人在并发编程中的经验及理解，希望能对你带来一些帮助。 JUC大神Doug Lea在JDK1.5中提供了Java并发包(JUC)，在java.util.concurrent这个包下提供了并发相关的工具类，例如锁、线程同步队列、线程池等等，但是如果你对其的原理不了解或者没有并发编程的相关经验，就很容易犯错。 线程池使用线程池时，我们应该明确线程池中的基本参数，了解其作用，这样才能更准确、有效的使用线程池，在《阿里巴巴Java开发手册》中对于线程池的创建说明如下： 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 返回的线程池对象的弊端如下： 1）FixedThreadPool 和 SingleThreadPool: ​ 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 2）CachedThreadPool 和 ScheduledThreadPool: ​ 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 所以在创建线程池时，需要明确该线程池的使用目的，有以下要点需要注意 使用无界队列和设置队列大小时需要谨慎，避免OOM； 线程数量和超时时间也需要明确分配，避免造成资源的浪费； 对于线程池的使用，最好不要轻易的共用线程池，对于CPU密集型任务和IO密集型任务需要进行区分； 最好重写线程工厂创建线程的newThread()方法定义线程名称，方便问题的排查； 最好在饱和策略中进行日志输出，了解在什么时候进行了饱和策略及线程池当前的状态； 捕获线程执行时的run()方法非受检异常，或者设置UncaughtExceptionHandler回调处理； 创建线程池时，务必重写ThreadFactory的newThread()方法： 12345678910111213@Overridepublic Thread newThread(Runnable r) &#123; //设置线程名称 Thread thread = new Thread(r,prefix + \"-\" + thisPoolCount + \"-\" + name + \"-\" + count.incrementAndGet()); //是否为守护线程 thread.setDaemon(isDaemon); //设置优先级 thread.setPriority(priority); //设置异常处理器 thread.setUncaughtExceptionHandler(uncaughtExceptionHandler); return thread;&#125; 设置线程的名称及是否为守护线程、优先级等属性，以及设置线程的异常处理器；如果线程中没有自己捕获非受检异常，当这个异常发生时，如果设置了异常处理器，那么我们可以通过UncaughtExceptionHandle的回调方法来处理该异常。 尤其是设置线程名称这一点尤为重要，如果项目中使用了多个线程池，在线程抛出异常或使用jstack命令查看堆栈信息时，看到的线程池中的线程名称都是pool-x-thread-x，这样不利于快速排查出现问题的所在线程，所以在创建线程池时，应该将线程的名称设置为与业务相关。 重写RejectedExecutionHandler的rejectedExecution()方法，在饱和策略中打印相关信息，以便排查问题： 12345678@Overridepublic void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; //饱和策略打印相关信息 log.warn(\"线程\" + r + \"执行饱和策略,当前线程池大小:\" + executor.getPoolSize() + \",当前活跃线程数:\"+executor.getActiveCount() + \",当前队列任务数:\" + executor.getQueue().size() + \",任务数:\"+executor.getTaskCount()); throw new RejectedExecutionException(\"线程池已满,执行饱和策略\");&#125; 重写ThreadPoolExecutor的beforeExecute()和afterExecute()方法，记录任务执行时间： 12345678910@Overrideprotected void beforeExecute(Thread t, Runnable r) &#123; startTime.set(System.currentTimeMillis()); log.info(\"开始执行任务\");&#125;@Overrideprotected void afterExecute(Runnable r, Throwable t) &#123; log.info(\"任务执行完成,执行耗时:\" + System.currentTimeMillis() - startTime.get());&#125; 并发Map在并发编程中，我们经常使用的并发Map应该就是ConcurrentHashmap了，但是很多开发人员对于并发Map的使用可能也是有问题的，以下是一个错误的案例： 12345678910private Map&lt;String,String&gt; concurrentHashmap = new ConcurrentHashMap&lt;&gt;();public String getValue(String key)&#123; String value = concurrentHashmap.get(key); if(null == value)&#123; value = createValue(key); concurrentHashmap.put(key,value); &#125; return value;&#125; 在这个案例中，value = createValue(key)这行代码可能会有并发问题，在这行代码中，存在多个线程同时执行的情况，那么在这种情况下，map中存放的值就会成为薛定谔的值，如果两个线程同时执行，就会丢失掉一次创建的value值，因为最终保存到该key中的value只有一个。 可以使用双重校验锁来规避以上这种情况： 123456789101112public String getValue1(String key)&#123; String value = concurrentHashmap.get(key); if(null == value)&#123; synchronized (concurrentHashmap) &#123; if (null == concurrentHashmap.get(key)) &#123; value = createValue(key); concurrentHashmap.put(key, value); &#125; &#125; &#125; return value;&#125; 也可以使用ConcurrentHashmap中自带的putIfAbsent()方法： 1234567891011public String getValue2(String key)&#123; String value = concurrentHashmap.get(key); if(null == value)&#123; value = createValue(key); String old = concurrentHashmap.putIfAbsent(key, value); if(null != old)&#123; value = old; &#125; &#125; return value;&#125; 具体采取哪种方法可能需要根据自身业务的场景来决定，但在双重校验锁中不会重复创建value，而putIfAbsent()方法是需要先创建value才决定是否put进去，这也是需要进行权衡的一点。 SimpleDateFormatSimpleDateFormat类相信大家都不陌生，我们经常采用它来进行时间的格式化操作，但是在使用这个类时也需要考虑其线程安全的问题，如果直接将该类作为全局变量来使用，那么就会引起错误： 1234567public class Test &#123; private SimpleDateFormat sdf = new SimpleDateFormat(\"dd/MM/yyyy\"); public String formatDate(Date date) &#123; return sdf.format(date); &#125;&#125; 查看SimpleDateFormat类的format()方法，发现其使用了全局共享变量calendar，因为该变量并不是线程安全的，所以在并发执行过程中就会发生错误： 123456789101112131415protected Calendar calendar;public StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos) &#123; pos.beginIndex = pos.endIndex = 0; return format(date, toAppendTo, pos.getFieldDelegate()); &#125;private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) &#123; // Convert input date to time field list calendar.setTime(date); ...&#125; 可以采用局部变量的方式使用SimpleDateFormat来解决该问题： 1234public String formatDate(Date date) &#123; SimpleDateFormat sdf = new SimpleDateFormat(\"dd/MM/yyyy\"); return sdf.format(date);&#125; 也可以采用ThreadLocal让每个线程持有一份SimpleDateFormat对象： 12345ThreadLocal&lt;SimpleDateFormat&gt; local = new ThreadLocal&lt;&gt;();public String formatDate(Date date) &#123; SimpleDateFormat sdf = local.get(); return sdf.format(date);&#125; 当然，也可以采用加锁的方式来避免问题的产生，在JDK8中，也可以采用DateTimeFormatter类来替代时间格式化的功能。 ThreadLocalThreadLocal 可能我们平常很少用到，但是在我们所使用的工具或框架中，经常能看见它的身影；ThreadLocal实际上就是用来维护本地线程中的变量，在Thread类的源码中，变量如下： 1ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal 的 get() 及 set() 方法源码如下： 1234567891011121314151617181920212223242526public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; ThreadLocal 的使用也很简单，使用案例如下： 123456ThreadLocal&lt;String&gt; localName = new ThreadLocal&lt;&gt;();public void xxx(String name)&#123; localName.set(name); //以下省略80行代码&#125; 当两个线程同时执行xxx()方法时，线程A的name值为zhangsan，线程B的name值为lisi，则示意图如下： 所以，当两个线程执行如下代码时，线程A获取的值为zhangsan，而线程B获取的值为lisi： 1String name = localName.get(); 每个ThreadLocal变量的值都保存到了各自线程中Thread的threadLocals变量里，也就是ThreadLocalMap中，如果创建多个ThreadLocal变量，则示意图如下： 谨防内存泄漏需要注意的一点是，在ThreadLocalMap中，它的Key是一个弱引用；也就是说它的Key在没有被外部对象强引用时，将会在下次GC时被回收，而它的Value却没有被回收，而这个访问不到的Value对象一直不会被回收，就发生了内存泄漏。 ThreadLocalMap的结构如下，通过Entry来保存K/V结构的数据，而key只能为ThreadLocal类型： 1234567891011static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private Entry[] table; ...&#125; 正确的使用ThreadLocal对象，应该在每次set()及get()处理完逻辑后，显式的调用remove()方法来清除数据来避免内存泄漏；在使用线程池的场景下，如果没有及时的清理ThreadLocal，则可能导致更严重的逻辑错误。","tags":[{"name":"并发","slug":"并发","permalink":"https://jinjinz.top/tags/并发/"}]},{"title":"Java虚拟机中的垃圾回收算法与垃圾收集器","date":"2019-08-01T07:35:13.000Z","path":"jvm/jvm-gc.html","text":"什么是垃圾回收（Garbage Collection,GC）？ 在程序的运行过程中，我们所创建的对象都会申请内存资源，当这个对象没有用处的时候，我们就需要将它的内存资源释放，否则造成内存资源的浪费，所以我们需要对内存资源进行管理。 在C/C++语言中，没有自动的垃圾回收机制，通过手动申请内存资源及手动释放内存资源来达到内存资源的控制，如果没有手动释放资源，则申请的对象占用的内存资源会一直占用，最终可能会导致内存溢出。 为了使得我们可以更专注与代码的实现而不用过多的考虑内存资源释放的问题，就需要一个垃圾回收机制来帮助我们在合速的时间，进行对垃圾对象的内存资源回收，将垃圾对象的内存资源释放。 什么对象是垃圾我们创建的对象实例都是放在Java堆中的，所以垃圾收集器的大部分时间也是在堆中的，垃圾收集器会判断堆中的哪些对象还在使用，哪些对象是垃圾，可以被回收。 方法区中也可以进行垃圾收集，回收废弃常量及无用的类，但是方法区中的垃圾收集性价比太低，所以在Java虚拟机规范中也不要求虚拟机在方法区实现垃圾收集。 引用计数法引用计数法是一个很经典的垃圾收集算法，它的实现很简单，就是给对象添加一个引用的计数器，有其他地方引用它时，计数器的值就增加1，当引用失效时，这个引用就减1。当对象的引用计数器为0时，这个对象就是不可能再被使用的状态。 如上图，对象A不再引用对象B后，对象B的引用计数器就会减1且到达0值，这时对象B不会再被其他任何对象使用到了，所以对象B需要被回收。 引用计数法的判断效率很高，在大部分情况下效果其实都不错，但是它确有个大问题，也就是引用计数法无法解决对象之间相互循环引用的问题。 如上图，实际上对象B和对象C已经不会再被使用到了，但是对象B和对象C的引用计数器都不为0。 可达性分析法在Java虚拟机的主流实现中，一般都是通过可达性分析来判断对象是否为垃圾。可达性分析法的基本思路为通过一系列被称为GC Roots的对象为起始点，从这些节点向下搜索，搜索到的路径称为引用链，如果一个对象到GC Roots没有任何引用链时，则说明这个对象是不可用的对象，可以被回收。 如下图，对象D、对象E、对象F虽然有引用关系，但是他们到GC Roots没有任何引用链，是不可达的对象，所以它们会被判断为可回收的对象。 在Java中，可作为GC Roots的对象包括下面几种： Java栈和本地方法栈中引用的对象。 方法区中类静态属性和常量引用的对象。 引用在判断对象是否是垃圾时，无论是引用计数法和可达性分析法，都是与引用有关。如果一个对象只有被引用和没有被引用两种状态，那么我们对于对象的引用操作空间就很小，例如我们希望在内存空间充足的时候保存一些对象，但是在内存资源比较紧缺的时候可以抛弃这些对象，这样的应用场景可以用在缓存上。 在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为了强引用、软引用、弱引用、虚引用4中引用。 强引用就是我们最常使用的引用，例如Object object = new Object就是强引用。 软引用用来描述在内存溢出前可以丢弃的对象，可以使用SoftReference类实现软引用。 弱引用用来描述下一次GC被回收的对象，可以使用WeakReference类实现弱引用。 虚引用是最弱的引用关系，一个对象是否有虚引用都不会对它的生命周期造成影响，虚引用的唯一目的就是在对象被回收时会受到通知，可以使用PhantomReference类实现虚引用。 对象复生如果对象实现了finalize()方法，且该方法还未被虚拟机调用过，那么这个对象在回收前会被加入F-Queue的队列中，在稍后由一个虚拟机建立的低优先级的Finalizer线程去执行。但虚拟机虽然会触发这个方法，但并不保证这个方法的执行结束，防止这个方法的执行过程太慢或者发生死循环等情况导致队列中的其他对象处于等待。 对象的finalize()方法只能被调用一次，如果在下一次被回收时对象的finalize()方法已经被调用过了，那么该方法不会再次执行，而且这个方法也是不建议使用的方法，我们往往有更好的方案来替代它。 垃圾收集算法各个平台的虚拟机操作内存的方法细节可能会有不同，但是垃圾收集的算法思路都是类似的。 标记清除法标记清除法是垃圾回收算法中的思想基础，标记清除法将垃圾回收分为标记和清除两个阶段。首先标记出从根节点开始可达的对象，未标记的对象就是可回收的对象，然后将这些对象进行回收。 但是标记清除法的最大问题就是会产生大量不连续的空间碎片，如下图所示，回收后的空间是不连续的： 复制算法复制算法算法将原有的内存空间分为两块，每次只使用其中的一块，在垃圾回收时，将还存活着的对象复制到另外一块上面，然后将这一块内存空间的所有对象清除。 如果垃圾对象很多，需要复制的存活对象数量就会相对较少，因此复制算法的效率还是很高的，并且将对象复制到新的内存空间中也保证了不会有空间碎片的存在；但是复制算法的代价是将内存折半。 如下图，将内存空间分为A、B两块，在A进行垃圾回收时，将A空间中的存活对象复制到B中，并将A空间清空： 在大多数时候采用复制算法来回收年轻代中的垃圾对象，而且因为大部分的对象死亡周期非常短暂，所以可以不用直接将内存折半，而是将内存使用8:1:1的比例分为了一个较大的Eden空间及2块Survivor空间。 当进行垃圾回收时，将Eden空间和Survivor空间中存活的对象复制到另一块Survivor空间上，然后清除Eden空间和刚刚使用的Survivor空间。每次使用的内存比例达到了百分之九十，只有百分之十的Survivor空间作为被复制的内存空间，每次复制后，两个Survivor空间的角色互换。 当Survivor空间的内存不够将对象复制进来时，需要老年代进行分配担保。也就是另外Survivor空间没有足够的内存存放收集到的存活对象时，这些对象直接会进入老年代。 标记压缩法复制算法如果在对象的存活率较高时，效率就会变低，在老年代中，大部分对象都是存活对象，所以复制算法的成本就会提高，所以基于老年代对象的特性，就需要使用其他算法。 基于老年代对象的特性，标记压缩法是在标记清除法的基础上优化得来的一直垃圾回收算法。和标记清除的过程一样，首先标记存活的对象，但之后并不是简单的清理未标记的对象，而是将存活的对象压缩到内存的一端。之后清理边界外的所有空间。 这种方法避免了空间碎片的产生，也不需要两块内存空间，因此性价比较高，标记压缩法的过程如下图所示： 垃圾收集器在Java虚拟机中，在什么情况下要使用什么类型的垃圾收集器以及这些垃圾收集器会造成什么样的影响，这是是我们需要了解的，只有了解了这些垃圾收集器的特点和使用方法，我们才能在具体的应用中使用合适的垃圾收集器。 串行收集器串行收集器是使用单线程进行垃圾回收的垃圾收集器，并且在进行垃圾回收时，必须暂停其他所有的工作线程，知道串行收集器的垃圾回收结束。 串行收集器可以在年轻代及老年代的内存空间中进行垃圾回收。 如下图所示，串行收集器在工作时，应用程序中的所有线程都需要停止工作，这种现象被称为Stop The World： 年轻代的串行收集器采用复制算法进行回收，老年代的串行收集器采用标记压缩法进行回收，串行收集器的实现相对简单且不用进行线程切换。在单CPU的硬件下性能还不错。 并行收集器并行收集器是串行收集器的多线程版本，并行收集器使用多个线程同时进行垃圾回收，对于并行能力较强的硬件情况下可以提高性能。 并行收集器同样可以在年轻代及老年代的内存空间中进行垃圾回收，回收策略与使用的算法都与串行收集器一样。 并行收集器工作过程如下图所示： 并行收集器由于存在线程交互的开销，在单CPU的环境中，串行收集器的效果会更好。但是随着CPU数量的增加，并行收集器的效率也会随之提升。 Parallel收集器Parallel收集器也可以在年轻代及老年代的内存空间中进行垃圾回收，回收策略与使用的算法都与并行收集器一样，且也是多线程的垃圾收集器。 Parallel收集器的特点是它的关注点与其他收集器不同，Parallel收集器的目标则是达到一个可控制的吞吐量。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 可以在JVM参数中配置Parallel收集器相关的参数进行控制。 CMS收集器CMS收集器是一种以获取最短回收停顿时间为目标的收集器，且在可以在应用程序运行过程中进行垃圾回收。 CMS收集器是基于标记清除法实现的，它的运作步骤如下： 初始标记，标记根对象 并发标记，标记回收对象 预处理，清理垃圾对象前的装备及控制停顿时间，也可以关闭预处理步骤 重新标记，修改并发标记中的对象 并发清除，清除垃圾 其中，初始标记、重新标记这两个步骤仍然需要Stop The World。 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。 整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作的，下图比较清楚地展示了CMS收集器的运作步骤中并发和需要停顿的时间： CMS是一款优秀的收集器，它的主要优点就是并发收集及低停顿。但是CMS对CPU资源的要求较高且会出现大量的空间碎片。 G1收集器G1收集器对内存进行了分区，虽然也会区分年轻代和老年代，但是G1对内存中的对象进行分区的回收，同时，G1收集器的特点如下： 并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，并且G1收集器的部分工作可以和应用程序同时运行。 分代收集：G1收集器能够同时管理年轻代和老年代，其他收集器都需要根据算法的不同为年轻代和老年代使用不同的垃圾收集器。 空间整理：G1从整体来看是基于标记压缩法实现的收集器，从分区上来看是基于复制算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行。 可预测性：G1可以只选择部分分区进行垃圾回收，达到对全局停顿的控制。 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代。而G1收集器的Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立分区（Region）。 G1收集器的内存模型如下： 在G1收集器中，使用记忆集合(Remembered Set，简称RSet)来避免全堆扫描。每个分区都有一个RSet，程序在对引用对象类型的数据进行写操作时，会产生一个Write Barrier(屏障)暂时中断写操作，检查这个引用的对象是否处于不同的分区之中；如果是，便把相关引用信息记录到被引用对象所属的分区的RSet之中。进行内存回收时，在GC根节点的枚举范围中加入RSet即可保证不对全堆扫描也不会有遗漏。 每个分区会被分为多个Card，所以在RSet中会记录对应分区中的Card，如下图所示 G1收集器的运作大致可划分为以下几个步骤： 初始标记，标记根对象 并发标记，标记回收对象 重新标记，修改并发标记中的对象 分区清理 其中，初始标记、重新标记这两个步骤和CMS收集器一样仍然需要Stop The World,在重新标记阶段会重新更新对象的记忆集合(Remembered Set)，最后在分区清理阶段首先对各个分区的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，根据区域的优先级进行回收。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://jinjinz.top/tags/JVM/"}]},{"title":"线程池ThreadPoolExecutor源码分析","date":"2019-07-07T02:20:18.000Z","path":"concurrent/threadpoolExecutor.html","text":"线程池的使用使用ThreadPoolExecutor来创建一个线程池： 12new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit,workQueue, handler); 创建一个线程池时需要传入几个参数，各参数的作用如下： corePoolSize：线程池的基本大小 提交一个任务到线程池时，如果当前执行的任务数小于线程池基本大小，线程池会新创建一个线程来执行任务。 workQueue：工作任务队列 当线程池的大小已经超过核心线程数后，新提交的任务保存至阻塞队列，阻塞队列的选择有以下几种： ArrayBlockingQueue：基于数组结构的有界阻塞队列，此队列按FIFO原则对元素进行排序。 LinkedBlockingQueue：基于链表结构的阻塞队列，此队列按FIFO原则对元素进行排序。 SynchronousQueue：不存储元素的阻塞队列。每个插入操作必须等待一个移除操作，否则插入操作一直处于阻塞状态。 PriorityBlockingQueue：一个具有优先级的无界阻塞队列。 maximumPoolSize：线程池最大数量 如果提交的任务不能保存到队列中(队列已满)，并且线程池的大小小于最大线程数，则线程池会再创建新的线程执行任务。 keepAliveTime：线程活跃存活时间 当线程池的工作线程空闲后，在活跃时间内没有执行任务，则对该线程进行回收 unit：线程活动保持时间的单位 通过TimeUnit类选择的单位有天、小时、分钟、毫秒、微秒和纳秒。 handler：饱和策略 当提交的任务不能保存到队列中且线程池的大小已经不小于最大线程数，那么说明该线程池处于饱和状态，此时需要采取一种饱和策略来处理新提交的任务。 饱和策略的默认选择为AbortPolicy，表示当线程池饱和时抛出异常。线程池框架还提供了以下3种策略： CallerRunsPolicy：直接在调用者线程中执行该任务。 DiscardOldestPolicy：执行队列的poll()方法，然后执行线程池的execute()方法再次提交到线程池。 DiscardPolicy：不进行任何处理，也就是将任务直接丢弃了。 如果想要扩展饱和策略，可以实现RejectedExecutionHandler接口自定义饱和策略。 线程池的实现原理当向线程池提交一个任务之后，线程池的简单处理流程如下： 如果线程池当前运行的线程没有超过核心线程数，则创建新线程来执行任务；否则将任务添加入队列中。 如果队列已满，则判断线程池当前运行的线程是否少于最大线程数，如果少于最大线程数，则创建新线程来执行任务。 如果创建新线程将使当前运行的线程超出最大线程数，将执行饱和策略。 线程池源码分析使用线程池的execute()向线程池提交任务，先从execute()方法开始作为查看源码入口 execute()execute()方法源码如下： 123456789101112131415161718192021222324public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果线程池当前运行的线程少于核心线程数，则创建新线程来执行任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //如果线程池当前运行的线程不少于核心线程数，则将任务添加入队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //再次检查是否需要添加新的线程 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如果线程池处于非运行状态,执行饱和策略 //如果之前的线程已被销毁，新建一个线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //如果队列已满，则创建新的线程来处理任务 else if (!addWorker(command, false)) reject(command); //如果创建新线程失败了，执行饱和策略&#125; addWorker()当工作线程数小于核心线程数的时候，会调用 addWorker()方法创建一个工作线程，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //goto for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //判断线程池是否处于运行状态,处于SHUTDOWN状态时判断队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //获得工作线程数 //如果工作线程数大于核心线程数或大于最大线程数，则返回false表示不能再添加新线程 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //cas增加工作线程数,cas失败则重试 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // 重新获取ctl的值 //如果线程状态发生变化,则重试 if (runStateOf(c) != rs) continue retry; &#125; &#125; boolean workerStarted = false; //工作线程启动标识 boolean workerAdded = false; //工作线程添加成功标识 Worker w = null; try &#123; w = new Worker(firstTask); //构建一个Worker,传入Runnable对象 final Thread t = w.thread; //从worker中取出线程 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); //使用重入锁，避免并发问题 try &#123; int rs = runStateOf(ctl.get()); //只有线程池是运行状态或是(SHUTDOWN且firstTask为空)，才添加到workers中 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //判断线程是否活跃 if (t.isAlive()) throw new IllegalThreadStateException(); workers.add(w); //将新创建的Worker添加到workers中 int s = workers.size(); //集合中的工作线程数 //如果集合中的工作线程数大于最大线程数 if (s &gt; largestPoolSize) largestPoolSize = s; //更新线程池出现过的最大线程数 workerAdded = true; //工作线程添加成功标识 &#125; &#125; finally &#123; mainLock.unlock(); //释放锁 &#125; //如果worker添加成功则启动线程 if (workerAdded) &#123; t.start(); workerStarted = true; //工作线程启动标识 &#125; &#125; &#125; finally &#123; if (! workerStarted) //如果添加失败，递减实际工作线程数,因为方法开始时增加了工作线程数 addWorkerFailed(w); &#125; return workerStarted; //返回结果&#125; 简单来讲就是使用cas操作将工作线程数递增，然后新建一个线程并启动。 Worker类addWorker()方法中构建了一个Worker类，并且把firstTask 封装到 worker 中，Worker类的源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; private static final long serialVersionUID = 6138294804551838833L; /** 这就是实际运行的工作线程 */ final Thread thread; /** 这是需要执行的任务 */ Runnable firstTask; /** 线程完成的任务数 */ volatile long completedTasks; Worker(Runnable firstTask) &#123; setState(-1); // 初始状态-1,防止runWorker()前中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; public void run() &#123; runWorker(this); &#125; protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; 从源码中可以看到，worker中保存了一个实际执行任务的线程thread，以及初始化时要被执行的任务firstTask；最终执行任务时，实际是调用了runWorker()方法。 worker类继承了AbstractQueuedSynchronizer(AQS)，使用AQS实现了独占锁的功能，但是它的tryAcquire()方法是不允许重入的，它的独占锁作用如下： 当前线程拥有独占锁，那就说明当前线程正在执行任务，当前线程不该被中断 如果当前线程没有拥有独占锁，说明当前线程处于空闲状态，可以对该线程进行中断操作 addWorkerFailed()在addWorker()方法中，如果添加 Worker失败则调用addWorkerFailed()方法做失败后的处理，源码如下： 123456789101112private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 如果添加 Worker失败后，判断Worker是否已经构造好了，如果Worker不为空则从workers中删除，且原子递减核心线程数的数量，之后执行tryTerminate()方法尝试结束线程池。 runWorker()调用Worker类的run()方法时，实际会调用runWorker()方法执行任务，该方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); //表示允许中断 boolean completedAbruptly = true; try &#123; //循环执行任务,如果task为空,调用getTask()方法获取task while (task != null || (task = getTask()) != null) &#123; w.lock(); //加锁使得shutdown()方法不会终止正在执行任务的worker // 线程池为stop时不接受新任务，不执行任务队列的任务，且中断正在执行的任务 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); //可以继承ThreadpoolExecutor重写 Throwable thrown = null; try &#123; task.run(); //执行任务的run()方法 &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); //可以继承ThreadpoolExecutor重写 &#125; &#125; finally &#123; task = null; //将完成的任务置空以便下一次循环 w.completedTasks++; //增加完成任务数 w.unlock(); //释放锁 &#125; &#125; completedAbruptly = false; &#125; finally &#123; //删除worker,及判断释放补充新的worker processWorkerExit(w, completedAbruptly); &#125;&#125; runWorker()方法主要处理了以下两件事： 循环执行task任务，如果task为空则调用getTask()方法获取task任务 如果getTask()方法取得的任务依然位空，则runWorker()方法执行完毕 getTask()在runWorker()方法中，worker 线程调用getTask()方法从阻塞队列中获取需要执行的任务，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940private Runnable getTask() &#123; boolean timedOut = false; //判断是否超时 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //判断线程池在shutdown状态时队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; //线程池在shutdown状态时队列为空或线程池为stop状态 &#125; int wc = workerCountOf(c); //如果线程池中的线程数量大于核心线程数量,则需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //如果timed为true,表示需要进行超时控制 //通过阻塞队列的poll()方法实现超时控制,参数则为keepaliveTime Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); //如果取到的任务为空,则表示超时,否则返回取到的任务 if (r != null) return r; timedOut = true; //超时回收标记 &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; processWorkerExit()runWorker()方法中的的 while 循环执行完毕以后，在 finally 块中会调用 processWorkerExit()方法来销毁工作线 程。processWorkerExit()方法源码如下： 123456789101112131415161718192021222324252627private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) //判断是否调整工作线程数 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; //结束 &#125; addWorker(null, false); &#125;&#125; 到此为止，从执行execute()方法提交任务开始，创建worke线程到执行任务以及最后到销毁线程的全部过程就结束了。","tags":[{"name":"并发","slug":"并发","permalink":"https://jinjinz.top/tags/并发/"}]},{"title":"Hashmap与ConcurrentHashmap原理分析","date":"2019-06-23T01:31:00.000Z","path":"concurrent/hashmap.html","text":"HashMap结构1234567891011121314151617transient Node&lt;K,V&gt;[] table;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; ... &#125;static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; boolean red; ...&#125; HashMap在JDK1.8中的结构为数组（默认长度：16）+ 单向链表 + 红黑树，在JDK1.7中没有红黑树。 Hash算法Hash算法是用于得到数组的下标位置的前戏 ①根据hash算法得到一个整形数②控制在数组的长度之间（默认长度16,则为0-15）之间③Key.hashCode int 32位，高16位和低16位异或运算。得到的结果就是hash算法。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; put()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //判断table是否为空,为空则初始化 if ((tab = table) == null || (n = tab.length) == 0) //初始化 n = (tab = resize()).length; //判断数组的节点位置是否为空,为空则将新节点插入 if ((p = tab[i = (n - 1) &amp; hash]) == null) //将新节点加入数组 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //判断数组的下标位置上有节点存在,且key相同,则覆盖节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果节点是红黑树结构,则加入树中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //将节点加入链表中 else &#123; //循环链表 for (int binCount = 0; ; ++binCount) &#123; //将不同的key插入链表尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果链表长度超过8,则转为红黑树结构 if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; &#125; //判断链表中是否有相同的key，如果有则替换 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; &#125; ... //判断数组大小是否需要扩容 if (++size &gt; threshold) resize(); ...&#125; 判断table是否为空，调用resize()方法进行初始化 计算出下标的位置，hash值&amp;(数组长度-1)，如果这个位置没有节点则直接插入节点 如果下标的位置有节点，则判断key是否相同，相同覆盖节点，否则插入节点 插入节点时，如果是红黑树结构，则插入红黑树中；如果是链表结构，则插入链表尾部，如果链表的长度大于8，则将链表转为红黑树结构；如果删除节点时，红黑树的结构小于6，则重新转为链表结构 插入节点后判断数组大小是否需要扩容，是否扩容由扩容因子决定，当前大小/16=扩容因子，扩容按默认容量的2的倍数扩容，扩容后将原来的数组数据移到当前数组中 数组扩容后转移部分链表中的数据，判断hash倒数第5位为0即要移动到新的位置，否则不变，并且只可能在原来的位置或原来的位置+原来数组长度。 并发缺陷resize()调整 HashMap 大小的时候，存在条件竞争。 因为如果两个线程都发现 HashMap 需要重新调整大小了，它们会同时试着调整大小。 在调整大小的过程中，存储在链表中的元素的次序会反过来。因为移动到新的 bucket 位置的时候，HashMap 并不会将元素放在链表的尾部，而是放在头部。如果条件竞争发生了，会造成链表出现环形。 所以在多线程并发的环境下不能使用 HashMap，推荐使用ConcurrentHashmap。 知识点为何HashMap的数组长度一定是2的次幂？ hashMap的数组长度保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致。 以及，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀。 上面的&amp;运算，高位是不会对结果产生影响的，我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 HashMap的链表是从头插入还是从尾部插入的 在jdk1.8之前是插入头部的，在jdk1.8中是插入尾部的。 ConcurrentHashmapJDK1.7使用Segment 分段锁技术，这里就不过多讨论了，下面主要介绍在JDK1.8进行优化后的源码实现。 JDK1.8中的CocurrentHashMap 抛弃了原有的 Segment 分段锁，采用了 CAS + synchronized 来保证并发安全性。其中的 val next 及table都用了 volatile 修饰，保证了可见性。 在JDK1.8中的CocurrentHashMap最大的特点是引入了 cas(Compare And Swap)，简单的说就是比较并交换。 cas有3个操作数，内存值 V、旧的预期值 A、要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值V修改为 B，否则什么都不做。 结构结构与Hashmap基本相同，但是ConcurrentHashmap的table字段加了volatile关键字修饰保证可见性。 1transient volatile Node&lt;K,V&gt;[] table; 同时，ConcurrentHashmap的Node中的val和next也用了 volatile 修饰。 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ...&#125; 字段sizeCtl用来控制表初始化和扩容，默认值为0，功能如下 1private transient volatile int sizeCtl; 当sizeCtl为-1时，表示table正在初始化 当sizeCtl小于-1时为 -(1+n)，n表示有n个线程正在进行扩容操作 如果 table 未初始化，表示table需要初始化的大小 如果 table 初始化完成，表示table的容量，默认是table大小的0.75倍 put()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //非空判断 if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); //计算hash值 int binCount = 0; //用来记录链表长度 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //检查table是否为空，为空则进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //判断节点是否为空，为空则使用cas存储节点 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果该下标的节点为空，则cas插入即可；如果cas失败，说明存在竞争，则进入下一次循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; //如果节点正在扩容，则协助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; //对节点加锁 synchronized (f) &#123; //如果table[i]为树节点，则将此节点插入树中即可。 //如果table[i]的节点是链表节点，则插入链表中。 ... &#125; //检查是否需要转化为树，如果需要则进行转化 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //调用addCount()方法增加元素个数 addCount(1L, binCount); return null;&#125; 检查table是否初始化了，如果没有，则调用initTable()方法进行初始化 根据key的hash值计算出其应该在table中储存的位置i，取出table[i]的节点用f表示。有以下三种情况： 如果table[i]位置的节点为空，没有发生碰撞， 则利用cas操作直接存储在该位置，如果cas操作成功则退出死循环，如果cas操作失败则进入下一次循环。 如果table[i]已经有其它节点，发生碰撞，则检查table[i]的节点的hash是否等于MOVED，如果等于，则检测到正在扩容，则帮助其扩容。如果table[i]的节点的hash值不等于MOVED，如果table[i]为链表节点，则将此节点插入链表中即可。 如果table[i]为树节点，则将此节点插入树中即可。如果table[i]的节点是链表节点，则插入链表中，然后检查是否需要转化为树，如果需要则进行转化 addCount()方法在putVal()方法完成后，会调用addCount()方法来增加ConcurrentHashMap中元素的个数，并且可能会触发扩容操作。putVal()方法调用addCount()方法传递的两个参数值分别是1 和 binCount(链表长度)。 addCount()方法有两个参数x和check，x 表示这次需要在表中增加的元素个数，check 参数表示是否需要进行扩容检查，大于等于 0 都需要进行检查 。 123456789101112131415161718192021222324252627private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //判断 counterCells 是否为空 //如果为空，则通过cas操作修改baseCount变量，进行原子增加操作 //如果不为空或cas失败，则通过CounterCell记录元素数量 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; //标识是否没有冲突，默认没有冲突 //如果counterCells为空则直接调用fullAddCount()方法 //从counterCells中随机取出一个数组的位置为空,直接调用fullAddCount()方法 //cas修改CounterCell随机位置的值,修改失败调用fullAddCount()方法 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)))&#123; //调用fullAddCount()方法 fullAddCount(x, uncontended); return; &#125; //如果链表长度小于等于 1，不需要考虑扩容 if (check &lt;= 1) return; //统计 ConcurrentHashMap 元素个数 s = sumCount(); &#125; ...&#125; CounterCells介绍ConcurrentHashMap 采用 CounterCell 数组来记录元素个数，也就是分片的方法来记录元素数量。 1234567891011121314151617181920212223//标识当前cell数组是否在初始化或扩容中的cas标志位private transient volatile int cellsBusy;// counterCells 数组，元素的数量分别存在每个CounterCell中private transient volatile CounterCell[] counterCells;@sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125;&#125;//CounterCell数组的每个元素，都存储一个元素个数，循环累加得到最终的总数final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; fullAddCount()方法fullAddCount()方法主要用来初始化 CounterCell，记录元素个数，包含扩容，初始化等操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; //获取当前线程的probe的值，如果值为0，则初始化当前线程的prob 的值,probe就是随机数 if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); wasUncontended = true; // 重新生成probe，未冲突标志位设置为 true &#125; boolean collide = false; for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; //如果counterCells已经被初始化了 if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; //通过当前线程probe进行与运算，获得cells 的下标元素 if ((a = as[(n - 1) &amp; h]) == null) &#123; //cellsBusy为0表示 counterCells 不在初始化或者扩容状态下 if (cellsBusy == 0) &#123; CounterCell r = new CounterCell(x); //传入元素个数 //通过cas设置 cellsBusy 标识，防止并发处理 if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean created = false; try &#123; CounterCell[] rs; int m, j; //将初始化的对象的元素个数放在对应下标的位置 if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; created = true; &#125; &#125; finally &#123; cellsBusy = 0; //恢复标志位 &#125; //创建成功则退出循环 if (created) break; continue; //创建未成功说明指定下标位置的数据不为空，进行下一次循环 &#125; &#125; collide = false; &#125; //说明在addCount()方法中 cas 失败了，并且获取 probe 的值不为空 else if (!wasUncontended) wasUncontended = true; //设置为未冲突标识，进入下一次自旋 //指定下标位置的不为空，则直接通过 cas 进行原子累加，如果成功，则直接退出 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; //如果已经有其他线程建立了新的 counterCells 或者 CounterCells 大于 CPU 核心数 else if (counterCells != as || n &gt;= NCPU) collide = false; //设置当前线程的循环失败不进行扩容 //恢复 collide 状态，标识下次循环会进行扩容 else if (!collide) collide = true; //如果竞争较大，设置正在扩容标识，进行扩容 else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; try &#123; if (counterCells == as) &#123; //扩容一倍 CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; counterCells = rs; &#125; &#125;finally &#123; cellsBusy = 0;//恢复标识 &#125; collide = false; continue; //继续下一次循环 &#125; h = ThreadLocalRandom.advanceProbe(h);//更新随机数的值 &#125; //如果counterCells还没被初始化，则进行初始化操作 else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean init = false; try &#123; if (counterCells == as) &#123; CounterCell[] rs = new CounterCell[2]; //初始化容量为 2 rs[h &amp; 1] = new CounterCell(x); //将元素的个数放在指定的数组下标位置 counterCells = rs; //赋值给 counterCells init = true;//设置初始化完成标识 &#125; &#125; finally &#123; cellsBusy = 0;//恢复标识 &#125; if (init) break; &#125; //其它线程占据 cell 数组，直接累加在 basecount 变量中 else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; &#125;&#125; 并发扩容在调用addCount()方法时，会根据传入的数量标识是否需要检查扩容，也就是当更新后的键值对总数大于阈值时，进行扩容。 如果当前正处于扩容阶段，则当前线程会加入并且协助扩容；如果当前没有在扩容，则直接触发扩容操作。 addCount()方法检查扩容代码如下： 1234567891011121314151617181920212223242526//如果传入的check大于等于0，则需要检查扩容if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //如果集合大小大于或等于扩容阈值,并且 table 不为空且长度小于最大容量 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); //生成一个唯一的扩容戳,这里划个重点 //如果sizeCtl小于0，说明已经有别的线程正在扩容了 if (sc &lt; 0) &#123; //判断是否能帮助进行此次扩容 //具体判断逻辑请看注1 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //当前线程帮助此次扩容，如果cas成功，则调用transfer()方法进行扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //如果当前没有在扩容，将sc设置为一个负数，+2 表示有一个线程在执行扩容 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount();// 重新计数，判断是否需要开启下一轮扩容 &#125;&#125; 注1： 当前线程判断是否能帮助进行此次扩容时，需先判断(sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT)的高位值与rs相等，如果相等，则还需满足以下4个条件： 如果sc = rs+1，则表示扩容结束 如果sc = rs+MAX_RESIZERS，则表示帮助线程线程已经达到最大值了 如果nt = nextTable，则表示扩容已经结束 如果transferIndex &lt;= 0，表示所有的 transfer 任务都被领取完了 resizeStamp()方法resizeStamp()方法用来生成一个和扩容有关的扩容戳，其代码如下： 123static final int resizeStamp(int n) &#123; return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&#125; Integer.numberOfLeadingZeros()方法是返回无符号整数 n 最高位非 0 位前面的 0 的个数。 如果n等于16，那么resizeStamp(16)的值为32796 将32796转换为二进制则为 [0000 0000 0000 0000 1000 0000 0001 1100] 当第一个线程进行尝试扩容时，会执行以下代码： 123//如果当前没有在扩容，将sc设置为一个负数，+2 表示有一个线程在执行扩容else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) RESIZE_STAMP_SHIFT的值为16，那么将rs左移16位，变成了[1000 0000 0001 1100 0000 0000 0000 0000] 之后在+2，则值为[1000 0000 0001 1100 0000 0000 0000 0010] 高 16 位代表扩容的标记、低 16 位代表并行扩容的线程数 transfer()方法transfer()方法就是进行扩容的方法，其代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //让每个CPU处理的桶一样多,默认一个线程处理16个桶 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; //如果nextTab为空,初始化nextTab,用来扩容 if (nextTab == null) &#123; try &#123; Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; //新建一个 n&lt;&lt;1 table大小的nextTab &#125; catch (Throwable ex) &#123; sizeCtl = Integer.MAX_VALUE; //扩容失败，sizeCtl使用int的最大值 return; &#125; nextTable = nextTab; //赋值成员变量 transferIndex = n; //表示转移时的下标 &#125; int nextn = nextTab.length; //新的 tab 的长度 // 创建一个 fwd 节点,表示一个正在被迁移的 Node ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; //如果等于 true,则处理下一个下标 boolean finishing = false; //扩容是否完成的标记 //循环处理每个槽位中的链表元素,i为当前槽位,bound为槽位边界 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; //循环分配任务 while (advance) &#123; int nextIndex, nextBound; //--i为下一个待处理的桶，如果它&gt;=bound,表示当前线程已经分配过桶 if (--i &gt;= bound || finishing) advance = false; //表示所有桶已经被分配完毕 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; //通过cas修改TRANSFERINDEX,为当前线程分配任务 //如果扩容的大小是32,则nextIndex=32,nextBound=16 //则处理的节点区间为(bound,i)-&gt;(16,31) //那么下一个进来的线程分配的区间就为(0,15) else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //i小于0 说明当前线程已经处理完所有负责的桶 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; //如果完成了扩容 if (finishing) &#123; nextTable = null; table = nextTab;//更新 table 数组 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);//更新阈值 return; &#125; //使用cas操作对 sizeCtl 的低16位进行减1，表示完成了自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; //如果还有线程在进行扩容,则扩容未结束 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; //如果扩容结束，更新finishing变量 i = n; //再次检查 &#125; &#125; //如果位置i处是空的，那么放入ForwardingNode节点 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //MOVED节点表示该位置已经完成了迁移 else if ((fh = f.hash) == MOVED) advance = true; else &#123; //对该节点位置加锁，开始迁移 synchronized (f) &#123; //再次校验 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn;//ln 表示低位，hn 表示高位; if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; //遍历当前节点的链表 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; //如果runBit 是 0，设置低位节点 if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; //否则设置高位节点 else &#123; hn = lastRun; ln = null; &#125; //构造高位以及低位的链表 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln);//将低位的链表放在i位置 setTabAt(nextTab, i + n, hn);//将高位链表放在 i+n 位置 setTabAt(tab, i, fwd); //将旧table的节点i设置为MOVED节点 advance = true; &#125; //红黑树部分省略 ... &#125; &#125; &#125; &#125;&#125; 协助扩容在执行put()方法时，如果table[i]已经有其它节点，发生碰撞，且table[i]的节点的hash等于MOVED，则线程帮助其扩容 12else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); helpTransfer()方法协助扩容，代码如下： 1234567891011121314151617181920212223final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; //判断此时是否仍然在执行扩容,如果nextTab为则扩容已经结束 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length);//生成扩容戳 //如果扩容还未完成,则循环尝试将当前线程加入到扩容操作中 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; //如果扩容已经结束,则退出循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; //退出循环 //在低16位中增加扩容线程数 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); //调用扩容方法协助扩容 break; &#125; &#125; return nextTab; &#125; return table;&#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://jinjinz.top/tags/并发/"}]},{"title":"重入锁-ReentrantLock底层源码分析","date":"2019-06-16T02:32:25.000Z","path":"concurrent/reentrantLock.html","text":"ReentrantLock使用： 123456789public class Demo &#123; private static int count=0; static Lock lock=new ReentrantLock(); public static void inc()&#123; lock.lock(); count++; lock.unlock(); &#125;&#125; ReentrantLock的使用很简单，调用lock()方法获得锁及unlock()方法释放锁。 AQS同步队列 AQS，全称 AbstractQueuedSynchronizer，它是一个同步的工具。AQS 队列内部维护的是一个 FIFO 的双向链表，每个节点都有两个指针，分别指向直接的后继节点和直接前驱节点。 当线程争抢锁失败后会封装为一个节点加入到 AQS队列中，当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点。 以下是一个AQS同步队列的基本结构： 当向AQS中添加节点时，变化如下： 将新的线程封装成 Node 节点追加到同步队列中，设置 prev 节点指向尾节点，以及将尾节点的next指针指向自己；之后通过CAS 将 tail 重新指向新的尾部节点。 AQS中的head节点即表示获取锁成功的节点，当头结点在释放同步状态时，会唤醒后继节点，如果后继节点获得锁成功，会把自己设置为头结点，节点的变化过程如下： 将head节点指向下一个获取到锁的节点，新获得锁的节点将prev指针指向null。 设置 head 节点不需要用 CAS，因为设置 head 节点是由获得锁的线程来完成的，而同步锁只能由一个线程获得。 ReentrantLock 源码分析以 ReentrantLock 作为切入点来看如何使用 AQS 来实现线程的同步。 ReentrantLock.lock()ReentrantLock.lock()方法为获取锁的入口，代码如下： 123public void lock() &#123; sync.lock();&#125; sync 是一个抽象的静态内部类，它继承了 AQS 来实现重入锁的逻辑，在不同的同步场景中，会继承 AQS 来实现对应场景的功能。 Sync 有两个具体的实现类，分别是： NofairSync 非公平锁：不管当前队列上是否存在其他线程等待，新线程都有机会抢占锁 FailSync 公平锁：表示所有线程严格按照 FIFO 来获取锁 以非公平锁为例来看 lock()方法中的实现 NofairSync.lock()非公平锁和公平锁最大的区别在于，在非公平锁中不管有没有线程排队，先使用cas 去尝试获取锁；cas成功，就表示成功获得了锁 ，cas失败，调用 acquire(1)走锁竞争逻辑 。 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; cas方法代码如下： 123protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 通过 cas 乐观锁的方式来做比较并替换，如果当前内存中的 state 的值和预期值 expect 相等，则替换为update。更新成功返回 true，否则返回 false。 state 是 AQS 中的一个属性，它在不同的实现中所表达的含义不一样，对于重入锁的实现来说，表示一个同步状态。当 state等于0时，表示无锁状态；当 state大于0时，表示已经有线程获得了锁，因为ReentrantLock 允许重入，所以同一个线程多次获得同步锁的时候，state 会递增， 而在释放锁的时候，需要相同次数直到state等于0 其他线程才有资格获得锁。 acquire()acquire 是 AQS 中的方法，如果 CAS 操作未能成功，说明 state 已经不为 0，此时执行acquire(1)操作。acquire方法的代码如下： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 首先通过tryAcquire()方法尝试获取锁，如果获取锁失败，则通过addWaiter()方法将当前线程封装为Node添加到AQS队列的尾部。 之后acquireQueued()方法将Node作为参数通过自旋去尝试获取锁。 tryAcquire()调用NofairSync非公平锁的尝试获取锁方法，成功返回true，失败返回false，代码如下： 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; 调用ReentrantLock.nofairTryAcquire()方法，代码如下： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取当前执行线程 int c = getState(); //获取state if (c == 0) &#123; //如果state等于0，则表示无锁 if (compareAndSetState(0, acquires)) &#123; //使用cas替换state的值 setExclusiveOwnerThread(current); //成功获得锁后保存当前线程，可重入 return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; //同一线程获取锁，增加重入次数 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 首先获取当前线程后判断当前锁状态，如果state等于0为无锁状态，则通过cas更新state的值，cas成功则成功获得锁；如果当前线程为重入线程，则直接增加重入次数。 addWaiter()如果获取锁失败，则通过addWaiter()方法将当前线程封装为Node添加到AQS队列的尾部。代码如下： 12345678910111213private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); //将当前线程封装为Node Node pred = tail; //获取当前AQS队列的tail节点 if (pred != null) &#123; //如果尾节点不为空，则设置当前节点为尾节点 node.prev = pred; //将当前线程的prev指针指向尾节点 if (compareAndSetTail(pred, node)) &#123; //通过cas操作将node设置为尾节点 pred.next = node; //设置成功后，将原尾节点的next指针指向当前node return node; &#125; &#125; enq(node); //尾节点为空或cas失败，通过enq()方法加入到AQS队列 return node;&#125; 首先将当前线程封装为Node，如果尾节点不为空，则通过cas将当前线程设置为AQS尾节点；如果尾节点为空或者cas失败则调用enq()方法将节点添加到AQS队列。 enq()方法代码如下： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; //自旋 Node t = tail; //获取当前AQS队列的tail节点 if (t == null) &#123; //如果尾节点为空，则初始化AQS队列 if (compareAndSetHead(new Node())) //通过cas操作设置头节点 tail = head; //初始化AQS队列，头节点和尾节点都是new Node(); &#125; else &#123; //如果尾节点不为空，则设置当前节点为尾节点 node.prev = t; //将当前线程的prev指针指向尾节点 if (compareAndSetTail(t, node)) &#123; //通过cas操作将node设置为尾节点 t.next = node; //设置成功后，将原尾节点的next指针指向当前node return t; &#125; &#125; &#125;&#125; enq()方法就是通过自旋操作把当前节点加入到队列中，只有在节点成功加入AQS队列后，才会跳出循环。 acquireQueued()将当前线程封装为Node添加到AQS队列后，acquireQueued()方法将Node作为参数通过自旋去尝试获取锁。该方法代码如下： 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //获取Node的前置节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //如果前置节点是head节点，则可以尝试获取锁 setHead(node); //获取锁成功，设置Node为新的head节点 p.next = null; //将原head节点的next指针设置为null,help GC failed = false; return interrupted; &#125; //调用shouldParkAfterFailedAcquire()方法判断是否需要挂起 //调用parkAndCheckInterrupt()将线程挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 获取当前节点的前置节点，如果前置节点为head节点，那么它就是下一个可以获取锁的幸运儿，所以有资格可以调用tryAcquire()方法尝试获取锁。 如果获取锁成功，则把获取锁的节点设置为head节点，将原来head节点的引用清除。如果获取锁失败，则需要调用shouldParkAfterFailedAcquire()方法判断是否需要挂起线程，parkAndCheckInterrupt()方法将线程挂起； shouldParkAfterFailedAcquire()方法代码如下： 123456789101112131415private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; //获取前置节点的状态 if (ws == Node.SIGNAL) //如果前置节点的状态为SIGNAL，则挂起当前线程 return true; if (ws &gt; 0) &#123; //如果前置节点状态大于0，则移除这个节点并重新获取前置节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); //循环移除状态大于0的节点 pred.next = node; &#125; else &#123; //cas设置前置节点的状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 通过Node的状态来判断获取锁失败后是否要被挂起。返回true时，表示需要调用调用parkAndCheckInterrupt()方法将当前线程挂起，返回false时，表示不需要挂起。 如果判断线程需要挂起，则调用parkAndCheckInterrupt()方法将线程挂起，代码如下： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 使用 LockSupport.park()方法挂起当前线程，线程状态变为WATING。 当线程重新被唤醒时，代码才继续往下执行，Thread.interrupted()方法返回当前线程是否被其他线程触发过中断请求，如果有触发过中断请求，那么这个方法会返回当前的中断标识true，并且对中断标识进行复位表示已经响应过了中断请求。 如果返回 true，意味着在 acquire()方法中会执行 selfInterrupt()方法。 selfInterrupt()方法的代码如下： 123static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 该方法就表示如果当前线程在 acquireQueued()方法中被中断过，则需要产生一个中断请求，原因是线程在调用 acquireQueued()方法的时候是不会响应中断请求的。 ReentrantLock.unlock()ReentrantLock.unlock()方法为释放锁的入口，代码如下： 123public void unlock() &#123; sync.release(1);&#125; release方法代码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //调用tryRelease()方法释放锁 Node h = head; //获取head节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //调用unparkSuccessor()方法唤醒后续节点 return true; &#125; return false;&#125; ReentrantLock.tryRelease()release()方法中调用tryRelease()方法来释放锁，该方法代码如下： 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 该方法将 state 状态减掉传入的参数值，如果结果状态为 0，就将锁的 Owner 设置为 null。 因为ReentrantLock允许重入，所以只有unlock()的次数与lock()的次数相同才能成功释放锁。 unparkSuccessor()release()方法中调用unparkSuccessor()方法唤醒后续节点，该方法代码如下： 12345678910111213141516 private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; //获取当前节点状态 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //设置当前节点状态为0 Node s = node.next; //获取下一个节点 if (s == null || s.waitStatus &gt; 0) &#123; //如果下一个节点为 null 或者 status&gt;0 表示节点为 cancelled 状态 s = null; //从尾部节点开始扫描，找到距离 head 最近的一个节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) //下一个节点状态正常，则直接唤醒 LockSupport.unpark(s.thread);&#125; acquireQueued()在线程被唤醒后，从acquireQueued()方法中重新开始执行，因为线程就是在该方法中被挂起的，代码如下： 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //获取Node的前置节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //如果前置节点是head节点，则可以尝试获取锁 setHead(node); //获取锁成功，设置Node为新的head节点 p.next = null; //将原head节点的next指针设置为null,help GC failed = false; return interrupted; &#125; //调用shouldParkAfterFailedAcquire()方法判断是否需要挂起 //调用parkAndCheckInterrupt()将线程挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 因为锁已经被释放，所以此时可以成功通过tryAcquire()方法获取锁，然后设置该线程尾新的head节点，且将原head节点的next指针设置为null。 以上便是ReentrantLock获取锁和释放锁的全部过程。","tags":[{"name":"并发","slug":"并发","permalink":"https://jinjinz.top/tags/并发/"}]},{"title":"Java虚拟机的基本认识及调优","date":"2019-05-03T08:55:16.000Z","path":"jvm/jvm.html","text":"Java虚拟机的基本认识虚拟机，从字面上的意义来理解就是一台虚拟的计算机，虚拟机上运行的软件都受限于虚拟机提供的资源中。 虚拟机可以分为两类，系统虚拟机和程序虚拟机，例如VMware提供了一个可以运行的操作系统的软件平台，这就是典型的系统虚拟机，我们可以像使用物理的计算机一样来使用VMware中提供的虚拟机。而Java虚拟机就是为了执行某个计算机程序而被设计出来的程序虚拟机，在Java虚拟机中执行的指令被称为Java字节码指令。 一个Java程序被编译成字节码，就可以通过Java虚拟机运行在各个操作系统平台中；也就是说Java程序通过Java虚拟机实现了跨平台的特性，如下图所示： 正是因为有了Java虚拟机，我们的Java程序在不同操作系统平台中运行时不需要重新编译，只要Java程序被编译为在Java虚拟机上运行的字节码，就可以在不同操作系统平台上运行。 Java虚拟机基本结构Java虚拟机的结构由以下几部分组成： 类加载器子系统类加载器子系统负责从文件或者网络中加载Class信息，加载后的类信息存放在方法区中。 对于任意一个类，都需要由加载他的类加载器和这个类本身一同确定其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。 类加载器子系统中的类加载器一共有三种类型，分别是启动类加载器、扩展类加载器和应用程序类加载器，各加载器的作用如下： 启动类加载器(Bootstrap ClassLoader)：负责将存放在&lt;JAVA_HOME&gt;\\lib目录或-Xbootclasspath参数指定的路径中的类库加载到内存中。该加载器由C++语言实现。 扩展类加载器(Extension ClassLoader)：负责加载&lt;JAVA_HOME&gt;\\lib\\ext目录或java.ext.dirs系统变量指定的路径中的所有类库。 应用程序类加载器(Application ClassLoader)：负责加载用户类路径上的指定类库，这是程序中默认的类加载器。 当一个类加载器收到了类加载的请求后，他首先不会自己去尝试加载这个类，而是把这个请求委派父类加载器去完成。因此所有的加载请求最终都会到顶层的启动类加载器中，只有当父加载器的加载范围中不需要加载这个类时，子加载器才会尝试自己去加载，这就是类加载器中的双亲委派模型。 双亲委任模型的实现代码实现在java.lang.ClassLoader中的loadClass方法之中，代码如下： 1234567891011121314151617181920212223242526272829303132333435protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 检查类是否已经加载 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //父类抛出异常表示无法完成加载请求 &#125; if (c == null) &#123; //调用自身的findClass()方法进行加载 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 运行时数据区Java虚拟机在执行Java程序的过程中会把它所管理的内存划分成若干个不同的数据区域，这些数据区域都有各自的用途，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 堆Java堆是Java程序主要的内存工作区域，堆中存放了Java的对象实例，且堆的空间是所有的线程共享的。 Java堆也是垃圾收集器管理的主要区域。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；且新生代一般还以8:1:1的空间划分出了一个Eden区和两个Survivor区。 方法区方法区与Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 Java栈每个线程都会有一个私有的Java栈，Java栈的生命周期与线程相同。每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈本地方法栈与Java栈类似，其区别在于Java栈用于Java方法的调用，而本地方法栈则用于本地方法的调用。本地方法一般使用C语言编写。 PC寄存器PC寄存器也是每个线程私有的空间，Java虚拟机会为每一个线程都创建PC寄存器。 如果线程正在执行的是一个Java方法，PC寄存器就会指向当前正在被执行的指令；如果正在执行的是Natvie方法，PC寄存器的值则为undefined。 直接内存直接内存并不是虚拟机运行时数据区的一部分。但是这部分内存也被频繁的使用，并且也可能导致内存溢出。 在JDK1.4中新加入NIO类,引入了一种基于Channel与Buffer的IO方式,它可以直接分配堆外内存,通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样避免了在Java堆和Native对中来回复制数据，能在一些场景中提高性能。 由于直接内存是在堆外的，因此直接内存的大小不会受限于堆的大小，但是系统的物理内存也是有限的，直接内存和堆内存的综合依然受限于操作系统中的最大内存。 执行引擎在不同的虚拟机实现里面，执行引擎在执行Java代码的时候可能会有解释执行和编译执行，也可能两者兼备。 但所有的Java虚拟机的执行引擎的核心功能都是输入字节码文件，然后将其编译为机器码后进行执行。 Java虚拟机配置参数在启动Java程序时，可以设置特定的Java虚拟机参数来进行系统调优或进行故障排查。 Java虚拟机中的配置参数可以分为三类，分别为标准参数、非标准参数和不稳定参数。 标准参数Java虚拟机中的标准参数，所有的Java虚拟机实现都必须实现这些参数的功能，并且向后兼容。 可以在命令行中使用 java -help 检索出所有的标准参数： 可以使用标准参数 -version 查看java虚拟机版本信息： 非标准参数Java虚拟机中的-X参数是非标准参数，Java虚拟机会实现这些参数的功能，但是并不保证所有Java虚拟机实现都满足，且不保证向后兼容；可以通过 java -X 检索出所有的非标准参数： 最常使用的两个非标准参数为-Xms和-Xmx分别是设置堆的初始化大小和最大大小。适当的调整jvm的内存大小，可以充分利用服务器资源，让程序得到性能的提升。 不稳定参数Java虚拟机中的-XX参数是不稳定参数。而且如果在新版本有什么改动也不会发布通知。这些参数中有很多对于我们来讲是非常有用的。 -XX参数的使用有2种方式，一种是boolean类型，一种是非boolean类型 boolean类型的选项为-XX:+ 打开， -XX:- 关闭。例如-XX:+DisableExplicitGC 表示禁用手动调用gc操作。 非boolean类型的选项通过-XX:= 设定。例如-XX:NewRatio=1 表示新生代和老年代的比值。 事实上不稳定参数也是我们在调优时最经常使用的参数，不稳定参数中的参数可以分为跟踪参数，堆参数及非堆参数3种类别。 跟踪参数在程序运行的时候，虚拟机提供了一些跟踪系统状态的参数，这些参数能对我们的故障排查有一定帮助；使用给定的参数就可以在程序运行时打印相关日志来帮助我们用于问题的分析。 我们可以添加一些跟踪参数来查看垃圾回收的效果。 简单的打印GC日志的参数为-XX:+PrintGC，在启动参数上添加后，则会打印简单的GC日志。 这个日志中一共进行了4次GC，在第一次GC时，在GC前堆空间的使用量为83133K，在GC后堆空间的使用量为21057K，当前可用的堆空间大小为129536K，最后显示的为本次GC所消耗的时间。 如果需要打印更详细的GC日志信息，可以使用-XX:+PrintGCDetails参数，该参数的输出例子如下： 堆参数堆空间在Java程序中是非常重要的部分，所以对于堆参数的配置也是对我们的程序性能有着重大影响的。 例如我们可以使用-XX:SurvivorRatio来设置年轻代中Eden区和Survivor区的比例大小以及参数-XX:NewRatio来设置新生代和老年代的比例。 有时在程序的运行过程中，可能会出现内存溢出的异常，可以使用相关参数来打印内存溢出时的堆信息，首先使用参数-XX:+HeapDumpOnOutOfMemoryError开启内存溢出时导出堆相关信息，然后在参数-XX:HeapDumpPath中配置导出堆信息时的路径或文件名。 非堆参数除了堆内存，我们还可以配置方法区、栈及直接内存的内存参数，合理的配置这些参数，也能对我们的应用程序性能的提高和稳定性产生作用。 使用-XX:MaxMetaspaceSize参数可以设置在JDK1.8中的元数据空间大小。 使用-XX:MaxDirectMemorySize参数可以设置直接内存的最大大小，默认为堆空间的最大大小，如果直接内存的内存溢出也会引起系统的OOM。 使用-XX:+DoEscapeAnalysis参数可以开启或关闭栈空间中对象的逃逸分析。 性能监控性能是无论如何在什么时候都需要关注的重要指标，所以我们需要有效的监控和诊断性能问题。 Linux下的性能监控很多Java程序都运行在Linux下，所以我们需要介绍下如何在Linux平台下进行性能监控。 系统整体资源使用情况top命令经常用来监控Linux的系统状况，比如cpu、内存的使用及进程的信息等等，top命令的输出样例如下： 在top命令输出的信息中，可以分为两个部分，上半部分是系统统计信息，下半部分是进程信息。 在系统统计信息中，第一行是任务队列信息，左边部分为系统当前时间，系统运行时间和当前登录用户数，右边的load average表示系统的平均负载，3个值分别表示1分钟、5分钟、15分钟到现在的平均值。 第二行是进程的统计信息，首先显示了所有的进程数，以及运行中的进程和睡眠的进程、停止状态的进程及僵尸进程。 第三行是CPU统计信息，这里显示了不同模式下所占用CPU时间的占用率，这些不同模式分别表示： us：用户空间的CPU占用率 sy：内核空间的CPU占用率 ni：改变过优先级的用户进程CPU占用率 id：CPU空闲的占用率 wa：等待输入输出的CPU占用率，也就是等待IO的CPU占用率 hi：处理硬件中断的CPU占用率 si：处理软件中断的CPU占用率 第四行的Mem及第五行的Swap是内存统计信息，Mem是物理内存使用，Swap是虚拟内存使用。total为全部可用内存，free为空闲内存，used为已使用内存，最后为缓冲区内存。 在top命令的下半部分则是进程信息，显示了系统内的进程资源使用情况，其中主要字段的含义如下： PID：进程ID USER：进程所有者的用户名 PR：进程的调度优先级 NI：进程的nice值，负值表示高优先级，正值表示低优先级 VIRT：进程使用的虚拟内存总量，VIRT=SWAP+RES RES：驻留内存大小。驻留内存是进程使用的、未被交换的物理内存大小。 SHR：共享内存大小。 S：进程状态。 %CPU：从上次更新到现在的CPU时间占用率。 %MEM：进程使用的物理内存百分比。 TIME+：进程使用的CPU时间，精确到百分之一秒。 COMMAND：运行进程所使用的命令。命令名/命令行 内存和CPU使用情况vmstat命令也可以用来监控Linux系统内存及CPU的使用情况，且可以指定采样周期及采用次数。 例如使用vmstat 1 5每秒采样一次，共计5次。 Procs（进程） r：等待运行的进程数 b：处在非中断睡眠状态的进程数 Memory（内存） swpd：虚拟内存使用情况 free：空闲内存 buff：用作缓冲区的内存大小 cache：用作缓存的内存大小 Swap si：每秒从磁盘交换区交换到内存的交换页 so：每秒从内存交换到磁盘交换区的交换页 IO bi：每秒读取的块数 bo：每秒写入的块数 System in：每秒中断数，包括时钟中断 cs：每秒上下文切换数 CPU us：用户空间CPU占用率 sy：内核空间CPU占用率 id：CPU空闲占用率 wa：等待输入输出的CPU占用率，也就是等待IO的CPU占用率 IO使用情况iostat命令将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。 同样的，iostat命令也可以指定采样周期及采用次数。以下例子采用了每秒采样一次，共计3次。 以上输出信息显示了CPU的使用概况及磁盘IO的信息。 CPU的属性值说明如下： %user：用户空间的CPU占用率 %nice：改变过优先级的用户进程CPU占用率 %system：内核空间的CPU占用率 %iowait：等待输入输出的CPU占用率，也就是等待IO的CPU占用率 %idle：CPU空闲的占用率 磁盘IO属性值说明如下： tps：该设备每秒的传输次数 kB_read/s：每秒从设备读取的数据量 kB_wrtn/s：每秒向设备写入的数据量 kB_read： 读取的总数据量 kB_wrtn：写入的总数据量 Java程序性能监控在JDK开发包中提供了一些的辅助工具，这些辅助工具可以帮助我们更好的去解决Java应用程序中出现的问题，在JDK安装目录下的bin目录中可以看到这些辅助工具。 查看Java进程jps命令与 linux 的 ps 命令有些类似，但是jps命令只会列出系统中的 Java 应用程序。 通过 jps 命令可以方便地查看 Java 进程的启动类、传入参数和 Java 虚拟机参数等信息。 如果直接运行jps命令，那么可以列出Java程序的进程ID及Main函数短名称。 jps命令的参数选项如下： -q：只输出进程 ID -m：输出传入 main 方法的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 查看堆内存使用情况jstat命令可以对Java应用程序的资源和性能进行实时的命令行的监控，包括了对堆大小和垃圾回收情况的监控。 jstat命令的参数选项如下： option：参数选项，这个参数的选项如下： -class ：显示ClassLoad的相关信息； -compiler ：显示JIT编译的相关信息； -gc：显示和gc相关的堆信息； -gccapacity：显示各个代的容量以及使用情况； -gcmetacapacity：显示metaspace的大小 -gcnew：显示新生代信息； -gcnewcapacity：显示新生代大小和使用情况； -gcold：显示老年代和永久代的信息； -gcoldcapacity ：显示老年代的大小； -gcutil：显示垃圾收集信息； -gccause：显示垃圾回收的相关信息，同时显示最后一次或当前正在发生的垃圾回收的原因； -t：显示系统运行的时间 -h：在周期性数据数据的时候，指定输出多少行以后输出一次表头信息 vmid：指定进程的 pid interval：输出统计信息的周期，单位为毫秒 count：输出统计信息的次数 查看class加载统计信息以下示例输出进程PID为17397的Java程序类加载信息。 输出信息说明如下： Loaded：加载类的数量 Bytes：加载类的大小 Unloaded：卸载类的数量 Bytes：卸载类的大小 Time：消耗时间 查看JIT编译统计信息 输出信息说明如下： Compiled：编译执行次数。 Failed：编译失败次数 Invalid：编译不可用次数 Time：消耗时间 FailedType：最后一次失败类型 FailedMethod：最后一次失败的类名及方法 查看GC统计信息 输出信息说明如下： S0C：第一个Survivor区的大小（KB） S1C：第二个Survivor区的大小（KB） S0U：第一个Survivor区的使用大小（KB） S1U：第二个Survivor区的使用大小（KB） EC：Eden区的大小（KB） EU：Eden区的使用大小（KB） OC：老年代大小 （KB） OU：老年代使用大小 （KB） MC：方法区大小（KB） MU：方法区使用大小（KB） CCSC：压缩类空间大小（KB） CCSU：压缩类空间使用大小（KB） YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：Full GC次数 FGCT：Full GC消耗时间 GCT：垃圾回收消耗总时间 导出堆信息及分析通过jstat命令可以对堆的内存进行统计分析，而jmap命令有更多功能，例如查看内存使用情况的汇总、对象实例的统计信息，导出堆的信息等等。 jmap中一个比较重要的功能就是将当前的堆信息快照保存到文件中，如下图： 将堆信息的快照导出后，可以使用各种工具对该文件进行分析，例如jhat命令工具或其他工具等等。 使用jhat命令可以用于分析导出的堆信息文件内容。 分析完成后，可以使用浏览器访问服务器的7000端口展示其分析结果，结果如下图所示： 该页面中显示了所有类信息，所有类的实例信息，点击链接进入后可以查看选中类的超类，类加载器及该类的实例信息等等信息。且在页面底部可以使用OQL进行查询。 可视化性能监控工具VisualVM工具能够监控线程，内存情况，查看方法的CPU时间和内存中的对象，已被GC的对象，查看分配的堆栈信息等等，是一个功能强大的可视化监控工具，且它的使用非常简单，可以完全替代其他JDK自带辅助工具的功能。 在JDK安装目录中的bin目录下可以直接启动VisualVM工具。 我们可以使用VisualVM工具连接本地Java程序或通过远程JMX连接Java程序。 VisualVM工具的主界面如下： 连接到本地进程后，可以查看进程中的JVM参数信息及版本信息： 以及查看CPU、堆、类和线程的统计信息： 以及查看线程信息： 并且点击线程Dump按钮后可以将线程信息导出： 并且可以使用抽样器对程序中的方法进行监控，有CPU和内存两个抽样器，通过CPU抽样器可以看出CPU中最消耗CPU资源的方法，通过内存抽样器可以动态的显示各个实例数据的大小：","tags":[{"name":"JVM","slug":"JVM","permalink":"https://jinjinz.top/tags/JVM/"}]},{"title":"自己动手写一个Spring框架","date":"2019-04-22T03:51:42.000Z","path":"spring/spring-code.html","text":"项目目的在理解 Spring 系统结构、实现原理的基础上，自己动手写一个实现Spring核心功能的框架，以达到学习的目的。 项目入口项目的入口为DispatcherSerlvet的init()方法中，在Servlet 的 init 方法初始化了IOC容器和Spring MVC所依赖的组件 项目搭建 本篇博客代码地址:https://github.com/jinzzzzz/spring-demo 用户配置application.properties配置application.properties作为配置文件，配置所需要的属性，配置如下： 1scanPackage=top.jinjinz.spring web.xml 配置配置自定义Servlet DispatcherServlet及设置匹配请求 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:javaee=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\" version=\"2.4\"&gt; &lt;display-name&gt;Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;servlet-class&gt;top.jinjinz.spring.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 项目配置build.gradle配置build.gradle配置相关的jar包依赖，目前只依赖了servlet api。 1234567891011121314subprojects &#123; apply plugin: 'java' group 'spring-demo' repositories &#123; mavenCentral() &#125; dependencies &#123; compile group: 'javax.servlet', name: 'javax.servlet-api', version: '3.1.0' &#125;&#125; 项目模块 项目名 项目描述 spring-core IOC容器/依赖注入 spring-webmvc web框架，基于Servlet spring-aop AOP框架 spring-test 测试项目 项目设计spring-aop实现切面功能，判断加上注解的类注册切面方法。 注解定义定义aop相关注解@After、@Aspect、@Before 12345678@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface After &#123; String value(); String argNames() default \"\";&#125; 12345@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface Aspect &#123; public String value() default \"\";&#125; 123456789@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface Before &#123; String value(); String argNames() default \"\";&#125; 接口定义Advice123456789package top.jinjinz.spring.aop;/** * Advice标签接口 * @author jinjin * @date 2019-04-22 */public interface Advice &#123;&#125; AopProxy12345678910111213package top.jinjinz.spring.aop;/** * AOP代理的接口 * @author jinjin * @date 2019-04-18 */public interface AopProxy &#123; Object getProxy(); Object getProxy(ClassLoader classLoader);&#125; Joinpoint1234567891011121314package top.jinjinz.spring.aop.intercept;/** * 连接点 * @author jinjin * @date 2019-04-18 */public interface Joinpoint &#123; Object proceed() throws Throwable; Object getThis();&#125; MethodInterceptor12345678910package top.jinjinz.spring.aop.intercept;/** * 方法调用过程中调用 * @author jinjin * @date 2019-04-18 */public interface MethodInterceptor &#123; Object invoke(MethodInvocation invocation) throws Throwable;&#125; MethodInvocation123456789101112131415package top.jinjinz.spring.aop.intercept;import java.lang.reflect.Method;/** * 方法拦截 * @author jinjin * @date 2019-04-18 */public interface MethodInvocation extends Joinpoint&#123; Method getMethod(); Object[] getArguments();&#125; 功能实现AdvisedSupport保存类方法执行时关联的调用链 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package top.jinjinz.spring.aop;import java.lang.reflect.Method;import java.util.List;import java.util.Map;import java.util.regex.Pattern;/** * AOP代理配置管理器的基类 * @author jinjin * @date 2019-04-18 */public class AdvisedSupport &#123; private Class&lt;?&gt; targetClass; private Object target; private Pattern pointCutClassPattern; /** 缓存方法为键，调用链列表为值 */ private transient Map&lt;Method, List&lt;Object&gt;&gt; methodCache; public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice( Method method,Class&lt;?&gt; targetClass) throws Exception &#123; List&lt;Object&gt; cached = this.methodCache.get(method); if (cached == null) &#123; Method m = targetClass.getMethod(method.getName(),method.getParameterTypes()); cached = methodCache.get(m); this.methodCache.put(method, cached); &#125; return cached; &#125; public Class&lt;?&gt; getTargetClass() &#123; return targetClass; &#125; public void setTargetClass(Class&lt;?&gt; targetClass) &#123; this.targetClass = targetClass; &#125; public Object getTarget() &#123; return target; &#125; public void setTarget(Object target) &#123; this.target = target; &#125; public Pattern getPointCutClassPattern() &#123; return pointCutClassPattern; &#125; public void setPointCutClassPattern(Pattern pointCutClassPattern) &#123; this.pointCutClassPattern = pointCutClassPattern; &#125; public Map&lt;Method, List&lt;Object&gt;&gt; getMethodCache() &#123; return methodCache; &#125; public void setMethodCache(Map&lt;Method, List&lt;Object&gt;&gt; methodCache) &#123; this.methodCache = methodCache; &#125;&#125; JdkDynamicAopProxy使用jdk动态代理，执行方法时，执行方法调用链 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package top.jinjinz.spring.aop;import top.jinjinz.spring.aop.intercept.MethodInvocation;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.List;/** * JDK动态代理实现&#123;@link AopProxy&#125; * @author jinjin * @date 2019-04-18 */public class JdkDynamicAopProxy implements AopProxy, InvocationHandler &#123; private final AdvisedSupport advised; public JdkDynamicAopProxy(AdvisedSupport config) throws Exception &#123; this.advised = config; &#125; @Override public Object getProxy() &#123; return getProxy(this.advised.getTargetClass().getClassLoader()); &#125; @Override public Object getProxy(ClassLoader classLoader) &#123; return Proxy.newProxyInstance( classLoader,this.advised.getTargetClass().getInterfaces(),this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice( method,this.advised.getTargetClass()); //如果没有可以应用到此方法的通知(Interceptor)，直接反射调用 if(null==chain)&#123; return method.invoke(proxy, args); &#125; MethodInvocation invocation = new ReflectiveMethodInvocation( proxy,advised.getTarget(),method,args,this.advised.getTargetClass(),chain); return invocation.proceed(); &#125;&#125; ProxyFactory生成代理对象 1234567891011121314151617181920212223242526272829303132333435package top.jinjinz.spring.aop;import java.lang.reflect.Proxy;/** * 用于AOP代理的工厂，用于编程使用，而不是通过声明性 * @author jinjin * @date 2019-04-18 */public class ProxyFactory extends AdvisedSupport&#123; public Object getProxy() throws Exception &#123; return createAopProxy().getProxy(); &#125; public Object getProxy(ClassLoader classLoader) throws Exception&#123; return createAopProxy().getProxy(classLoader); &#125; private synchronized AopProxy createAopProxy() throws Exception&#123; Class&lt;?&gt; targetClass = getTargetClass(); if (targetClass == null) &#123; throw new Exception(\"没有代理目标类\"); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(this); &#125; //todo 没有继承接口的类需要cglib代理 //return new ObjenesisCglibAopProxy(config); return new JdkDynamicAopProxy(this); &#125;&#125; ReflectiveMethodInvocation执行方法调用链 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package top.jinjinz.spring.aop;import top.jinjinz.spring.aop.intercept.MethodInterceptor;import top.jinjinz.spring.aop.intercept.MethodInvocation;import java.lang.reflect.Method;import java.util.List;import java.util.Map;/** * aop实现类 * @author jinjin * @date 2019-04-18 */public class ReflectiveMethodInvocation implements MethodInvocation &#123; protected final Object proxy; protected final Object target; protected final Method method; protected Object[] arguments = new Object[0]; private final Class&lt;?&gt; targetClass; private Map&lt;String, Object&gt; userAttributes; protected final List&lt;?&gt; interceptorsAndDynamicMethodMatchers; //定义一个索引，从-1开始来记录当前拦截器执行的位置 private int currentInterceptorIndex = -1; public ReflectiveMethodInvocation( Object proxy,Object target, Method method,Object[] arguments, Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers) &#123; this.proxy = proxy; this.target = target; this.targetClass = targetClass; this.method = method; this.arguments = arguments; this.interceptorsAndDynamicMethodMatchers = interceptorsAndDynamicMethodMatchers; &#125; @Override public Method getMethod() &#123; return this.method; &#125; @Override public Object[] getArguments() &#123; return this.arguments; &#125; @Override public Object proceed() throws Throwable &#123; //如果Interceptor执行完了，则执行joinPoint if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return this.method.invoke(this.target,this.arguments); &#125; Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get( ++this.currentInterceptorIndex); //动态匹配joinPoint if (interceptorOrInterceptionAdvice instanceof MethodInterceptor) &#123; MethodInterceptor mi = (MethodInterceptor) interceptorOrInterceptionAdvice; return mi.invoke(this); &#125; else &#123; //动态匹配失败时,略过当前Intercetpor,调用下一个Interceptor return proceed(); &#125; &#125; @Override public Object getThis() &#123; return this.target; &#125;&#125; AutoProxyCreator实现BeanPostProcessor接口，在初始化bean时调用，此时创建代理对象并加入调用方法链 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package top.jinjinz.spring.aop.autoproxy;import top.jinjinz.spring.aop.AdvisedSupport;import top.jinjinz.spring.aop.ProxyFactory;import top.jinjinz.spring.aop.adapter.AfterReturningAdviceInterceptor;import top.jinjinz.spring.aop.adapter.MethodBeforeAdviceInterceptor;import top.jinjinz.spring.aop.annotation.After;import top.jinjinz.spring.aop.annotation.AfterThrowing;import top.jinjinz.spring.aop.annotation.AopProxyUtils;import top.jinjinz.spring.aop.annotation.Before;import top.jinjinz.spring.aop.aspectj.AspectJAdvice;import top.jinjinz.spring.beans.factory.BeanFactory;import top.jinjinz.spring.beans.factory.config.BeanPostProcessor;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 自动创建代理 * @author jinjin * @date 2019-04-18 */public class AutoProxyCreator implements BeanPostProcessor &#123; private final Map&lt;String,List&lt;AspectJAdvice&gt;&gt; aspectMethods; private final List&lt;String&gt; patterns; public AutoProxyCreator(Map&lt;String, List&lt;AspectJAdvice&gt;&gt; aspectMethods, List&lt;String&gt; patterns) &#123; this.aspectMethods = aspectMethods; this.patterns = patterns; &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName, BeanFactory beanFactory) throws Exception &#123; if (bean != null) &#123; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.setTarget(bean); proxyFactory.setTargetClass(bean.getClass()); proxyFactory.setMethodCache( getMethodCathe(proxyFactory,beanFactory,Before.class)); return proxyFactory.getProxy(); &#125; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName, BeanFactory beanFactory) throws Exception &#123; if (bean != null) &#123; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.setTarget(bean); proxyFactory.setTargetClass(bean.getClass()); proxyFactory.setMethodCache( getMethodCathe(proxyFactory,beanFactory,After.class)); return proxyFactory.getProxy(); &#125; return bean; &#125; private List&lt;Object&gt; getAdvices( String p,BeanFactory beanFactory,Class&lt;? extends Annotation&gt; annotationClass) throws Exception&#123; List&lt;Object&gt; advices = new ArrayList&lt;&gt;(); List&lt;AspectJAdvice&gt; aspectJAdviceList = aspectMethods.get(p); for (AspectJAdvice aspectJAdvice:aspectJAdviceList) &#123; //注入 if(aspectJAdvice.getAspectTarget() instanceof String)&#123; aspectJAdvice.setAspectTarget( beanFactory.getBean((String)aspectJAdvice.getAspectTarget())); &#125; if(aspectJAdvice.getAspectMethod().isAnnotationPresent(Before.class))&#123; advices.add(new MethodBeforeAdviceInterceptor(aspectJAdvice)); &#125;else if(aspectJAdvice.getAspectMethod().isAnnotationPresent(After.class))&#123; advices.add(new AfterReturningAdviceInterceptor(aspectJAdvice)); &#125; &#125; return advices; &#125; private Map&lt;Method, List&lt;Object&gt;&gt; getMethodCathe( AdvisedSupport advisedSupport,BeanFactory beanFactory, Class&lt;? extends Annotation&gt; annotationClass) throws Exception&#123; Map&lt;Method, List&lt;Object&gt;&gt; methodCache = new HashMap&lt;&gt;(); Method[] methods=advisedSupport.getTargetClass().getMethods(); List&lt;Object&gt; advices; Matcher matcher; String methodString; Pattern pattern; for (Method method:methods) &#123; methodString = method.toString(); if(methodString.contains(\"throws\"))&#123; methodString = methodString.substring(0,methodString.lastIndexOf(\"throws\")).trim(); &#125; //判断所有的Aspect中的方法上的正则查看是否匹配 for (String p:patterns)&#123; pattern = Pattern.compile(p); matcher = pattern.matcher(methodString); if(matcher.matches())&#123; advices = getAdvices(p,beanFactory,annotationClass); methodCache.put(method,advices); break; &#125; &#125; &#125; return methodCache; &#125;&#125; AspectJAdvice保存配置需要切面执行的方法及方法的类 12345678910111213141516171819202122232425262728293031323334package top.jinjinz.spring.aop.aspectj;import java.lang.reflect.Method;/** * 执行属性 * @author jinjin * @date 2019-04-22 */public class AspectJAdvice &#123; private Method aspectMethod; private Object aspectTarget; public AspectJAdvice(Method aspectMethod, Object aspectTarget) &#123; this.aspectMethod = aspectMethod; this.aspectTarget = aspectTarget; &#125; public Method getAspectMethod() &#123; return aspectMethod; &#125; public void setAspectMethod(Method aspectMethod) &#123; this.aspectMethod = aspectMethod; &#125; public Object getAspectTarget() &#123; return aspectTarget; &#125; public void setAspectTarget(Object aspectTarget) &#123; this.aspectTarget = aspectTarget; &#125;&#125; AbstractAspectJAdviceAdvice的抽象类，定义基本功能，执行配置的切面方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445package top.jinjinz.spring.aop.aspectj;import top.jinjinz.spring.aop.Advice;import top.jinjinz.spring.aop.annotation.AopProxyUtils;import top.jinjinz.spring.aop.intercept.Joinpoint;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * 基类 &#123;@link top.jinjinz.spring.aop.Advice&#125; * @author jinjin * @date 2019-04-22 */public abstract class AbstractAspectJAdvice implements Advice &#123; private AspectJAdvice aspectJAdvice; public AbstractAspectJAdvice(AspectJAdvice aspectJAdvice) &#123; this.aspectJAdvice = aspectJAdvice; &#125; protected Object invokeAdviceMethod(Joinpoint joinPoint, Object returnValue, Throwable tx) throws Throwable&#123; Class&lt;?&gt; [] paramTypes = this.aspectJAdvice.getAspectMethod().getParameterTypes(); if(paramTypes.length == 0)&#123; return this.aspectJAdvice.getAspectMethod().invoke( aspectJAdvice.getAspectTarget()); &#125;else&#123; Object [] args = new Object[paramTypes.length]; for (int i = 0; i &lt; paramTypes.length; i ++) &#123; if(paramTypes[i] == Throwable.class)&#123; args[i] = tx; &#125;else if(paramTypes[i] == Object.class)&#123; args[i] = returnValue; &#125;else if(paramTypes[i] == Joinpoint.class)&#123; args[i] = joinPoint; &#125; &#125; return this.aspectJAdvice.getAspectMethod().invoke( AopProxyUtils.getTargetObject(aspectJAdvice.getAspectTarget()),args); &#125; &#125;&#125; MethodBeforeAdviceInterceptor方法调用之前执行，继承了AbstractAspectJAdvice类 123456789101112131415161718192021222324252627282930313233package top.jinjinz.spring.aop.adapter;import top.jinjinz.spring.aop.aspectj.AbstractAspectJAdvice;import top.jinjinz.spring.aop.aspectj.AspectJAdvice;import top.jinjinz.spring.aop.intercept.Joinpoint;import top.jinjinz.spring.aop.intercept.MethodInterceptor;import top.jinjinz.spring.aop.intercept.MethodInvocation;import java.lang.reflect.Method;/** * 拦截器-before * @author jinjin * @date 2019-04-19 */public class MethodBeforeAdviceInterceptor extends AbstractAspectJAdvice implements MethodInterceptor &#123; private Joinpoint joinPoint; public MethodBeforeAdviceInterceptor(AspectJAdvice aspectJAdvice) &#123; super(aspectJAdvice); &#125; private void before(Method method,Object[] args,Object target) throws Throwable&#123; super.invokeAdviceMethod(this.joinPoint,null,null); &#125; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; this.joinPoint = methodInvocation; before(methodInvocation.getMethod(), methodInvocation.getArguments(), methodInvocation.getThis()); return methodInvocation.proceed(); &#125;&#125; AfterReturningAdviceInterceptor方法调用之后执行，继承了AbstractAspectJAdvice类 12345678910111213141516171819202122232425262728293031323334package top.jinjinz.spring.aop.adapter;import top.jinjinz.spring.aop.aspectj.AbstractAspectJAdvice;import top.jinjinz.spring.aop.aspectj.AspectJAdvice;import top.jinjinz.spring.aop.intercept.Joinpoint;import top.jinjinz.spring.aop.intercept.MethodInterceptor;import top.jinjinz.spring.aop.intercept.MethodInvocation;import java.lang.reflect.Method;/** * 拦截器-after * @author jinjin * @date 2019-04-22 */public class AfterReturningAdviceInterceptor extends AbstractAspectJAdvice implements MethodInterceptor &#123; private Joinpoint joinPoint; public AfterReturningAdviceInterceptor(AspectJAdvice aspectJAdvice) &#123; super(aspectJAdvice); &#125; private void afterReturning(Object retVal,Method method, Object[] args, Object target) throws Throwable&#123; super.invokeAdviceMethod(this.joinPoint,null,null); &#125; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; Object retVal = methodInvocation.proceed(); this.joinPoint = methodInvocation; this.afterReturning(retVal,methodInvocation.getMethod(), methodInvocation.getArguments(),methodInvocation.getThis()); return retVal; &#125;&#125; AopProxyUtils获取aop代理前的原始类 123456789101112131415161718192021222324252627282930313233343536package top.jinjinz.spring.aop.annotation;import top.jinjinz.spring.aop.AdvisedSupport;import top.jinjinz.spring.aop.AopProxy;import java.lang.reflect.Field;import java.lang.reflect.Proxy;/** * aop工具类 * @author jinjin * @date 2019-04-22 */public class AopProxyUtils &#123; public static Object getTargetObject(Object proxy) throws Exception&#123; if(!isAopProxy(proxy))&#123; return proxy; &#125; return getProxyTargetObject(proxy); &#125; private static boolean isAopProxy(Object object)&#123; return Proxy.isProxyClass(object.getClass()); &#125; private static Object getProxyTargetObject(Object proxy) throws Exception&#123; Field h = proxy.getClass().getSuperclass().getDeclaredField(\"h\"); h.setAccessible(true); AopProxy aopProxy = (AopProxy) h.get(proxy); Field advised = aopProxy.getClass().getDeclaredField(\"advised\"); advised.setAccessible(true); AdvisedSupport advisedSupport = (AdvisedSupport)advised.get(aopProxy); return getTargetObject(advisedSupport.getTarget()); &#125;&#125; spring-core实现Spring的IOC容器及依赖注入功能 注解定义注解模块，实现@Autowrited、@Service、@RequestParam、@RequestMapping、@Controller等注解 @Autowired 12345678910111213package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * 自动装配注解 * @author jinjin * @date 2019-03-25 */@Target(&#123;ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Autowired &#123; String value() default \"\";&#125; @Service 1234567891011121314package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * Service注解 * @author jinjin * @date 2019-03-25 */@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service &#123; String value() default \"\";&#125; @Component 12345678910111213package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * 组件标识 * @author jinjin * @date 2019-04-18 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Component &#123; String value() default \"\";&#125; @RequestParam 12345678910111213package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * 请求参数注解 * @author jinjin * @date 2019-03-25 */@Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RequestParam &#123; String value() default \"\";&#125; @RequestMapping 12345678910111213package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * 请求地址映射注解 * @author jinjin * @date 2019-03-25 */@Target(&#123;ElementType.TYPE,ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RequestMapping &#123; String value() default \"\";&#125; @Controller 1234567891011121314package top.jinjinz.spring.beans.factory.annotation;import java.lang.annotation.*;/** * 控制器注解 * @author jinjin * @date 2019-03-25 */@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller &#123; String value() default \"\";&#125; 接口定义BeanFactory创建Bean的工厂，也就是IOC容器，BeanFactory 作为基础的接口类，定义了 IOC 容器的基本功能。 123456789101112package top.jinjinz.spring.beans.factory; /** * 定义IOC容器的基本功能接口 * author:jinjin * Date:2019/4/13 22:19 */public interface BeanFactory &#123; //根据bean的名字，获取在IOC容器中得到bean实例 Object getBean(String name) throws Exception;&#125; ApplicationContext定义ApplicationContext接口，继承BeanFactory的功能并扩展其功能，默认初始化所有bean。 123456789101112package top.jinjinz.spring.context;import top.jinjinz.spring.beans.factory.BeanFactory; /** * 扩展BeanFactory功能 * author:jinjin * Date:2019/4/14 3:44 */public interface ApplicationContext extends BeanFactory &#123; String[] getBeanDefinitionNames();&#125; BeanDefinition存储对Bean的解析信息类，BeanDefinition存储了解析后的Bean元信息 123456789101112131415161718192021package top.jinjinz.spring.beans.factory.config;/** * 存储对Bean的解析信息 * author:jinjin * Date:2019/4/13 23:16 */public interface BeanDefinition &#123; void setBeanClassName(String beanClassName); String getBeanClassName(); void setLazyInit(boolean lazyInit); boolean isLazyInit(); void setFactoryBeanName(String factoryBeanName); String getFactoryBeanName();&#125; BeanPostProcessor在初始化bean时回调接口 12345678910111213141516171819202122package top.jinjinz.spring.beans.factory.config;import top.jinjinz.spring.beans.factory.BeanFactory;/** * 允许自定义修改代理的实例的工厂钩子 * @author jinjin * @date 2019-04-18 */public interface BeanPostProcessor &#123; //为在Bean的初始化前提供回调入口 default Object postProcessBeforeInitialization(Object bean, String beanName, BeanFactory beanFactory) throws Exception &#123; return bean; &#125; //为在Bean的初始化之后提供回调入口 default Object postProcessAfterInitialization(Object bean, String beanName, BeanFactory beanFactory) throws Exception &#123; return bean; &#125;&#125; BeanDefinitionReader将配置信息解析为BeanDefinition的类 1234567891011121314151617package top.jinjinz.spring.beans.factory.support;import java.io.IOException;/** * 将Bean定义信息读取为BeanDefinition * @author jinjin * @date 2019-04-15 */public interface BeanDefinitionReader &#123; BeanDefinitionRegistry getRegistry(); int loadBeanDefinitions(String location) throws IOException; int loadBeanDefinitions(String... locations) throws IOException;&#125; BeanDefinitionRegistry注册BeanDefinition并保存的类 12345678910111213141516171819202122232425262728package top.jinjinz.spring.beans.factory.support;import top.jinjinz.spring.beans.factory.config.BeanDefinition;import top.jinjinz.spring.beans.factory.config.BeanPostProcessor;/** * 保存BeanDefinition的容器 * @author jinjin * @date 2019-04-15 */public interface BeanDefinitionRegistry &#123; void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws Exception; void removeBeanDefinition(String beanName); BeanDefinition getBeanDefinition(String beanName); boolean containsBeanDefinition(String beanName); String[] getBeanDefinitionNames(); int getBeanDefinitionCount(); //增加bean回调处理器 void addBeanPostProcessor(BeanPostProcessor beanPostProcessor);&#125; 功能实现DefaultListableBeanFactoryBeanFactory的默认实现类，也实现了BeanDefinitionRegistry接口，保存了BeanDefinition信息，实现了基本的依赖注入功能和IOC容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181package top.jinjinz.spring.beans.factory.support; import top.jinjinz.spring.beans.factory.BeanFactory;import top.jinjinz.spring.beans.factory.annotation.Autowired;import top.jinjinz.spring.beans.factory.config.BeanDefinition;import top.jinjinz.spring.beans.factory.config.BeanPostProcessor;import java.lang.reflect.Field;import java.util.*;import java.util.concurrent.ConcurrentHashMap;/** * BeanFactory的默认实现 * author:jinjin * Date:2019/4/14 4:00 */public class DefaultListableBeanFactory implements BeanFactory,BeanDefinitionRegistry &#123; //存储注册信息的BeanDefinition private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); /** 缓存singleton类型实例: bean name --&gt; bean instance */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); /** 正在创建的bean集合 */ private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); /** 创建bean时应用的处理器 */ private final List&lt;BeanPostProcessor&gt; beanPostProcessors = new ArrayList&lt;&gt;(); @Override public Object getBean(String name) throws Exception&#123; return doGetBean(name); &#125; @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws Exception&#123; this.beanDefinitionMap.put(beanName, beanDefinition); &#125; @Override public void removeBeanDefinition(String beanName) &#123; this.beanDefinitionMap.remove(beanName); &#125; @Override public BeanDefinition getBeanDefinition(String beanName)&#123; BeanDefinition beanDefinition = this.beanDefinitionMap.get(beanName); return beanDefinition; &#125; @Override public boolean containsBeanDefinition(String beanName) &#123; return this.beanDefinitionMap.containsKey(beanName); &#125; @Override public String[] getBeanDefinitionNames() &#123; return this.beanDefinitionMap.keySet().toArray(new String[0]); &#125; @Override public int getBeanDefinitionCount() &#123; return this.beanDefinitionMap.size(); &#125; @Override public void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; this.beanPostProcessors.remove(beanPostProcessor); this.beanPostProcessors.add(beanPostProcessor); &#125; //从容器中获取beanDefinition，如果没有创建实例则创建实例并初始化 private Object doGetBean(final String beanName) throws Exception&#123; //先从缓存中取已经被创建的singleton类型的Bean Object singletonInstance = this.singletonObjects.get(beanName); if(null != singletonInstance)&#123; return singletonInstance; &#125; //循环引用 if(singletonsCurrentlyInCreation.contains(beanName))&#123; throw new RuntimeException(beanName+\"发生循环引用\"); &#125; //开始创建单例的实例 Object instance = null; BeanDefinition beanDefinition = this.beanDefinitionMap.get(beanName); if(null == beanDefinition)&#123; throw new RuntimeException(beanName+\"不存在\"); &#125; Class&lt;?&gt; clazz = Class.forName(beanDefinition.getBeanClassName()); instance = clazz.newInstance(); populateBean(instance,beanDefinition,clazz); instance = applyBeanPostProcessorsBeforeInitialization(instance, beanName); //将类名和注解值都作为key值放入map,接口将类型名称存入 this.singletonObjects.put(beanDefinition.getBeanClassName(),instance); this.singletonObjects.put(beanDefinition.getFactoryBeanName(),instance); return instance; &#125; //调用BeanPostProcessor 初始化调用实例之前的处理方法 private Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws Exception &#123; Object result = existingBean; //遍历容器为所创建的Bean添加的所有BeanPostProcessor for (BeanPostProcessor beanProcessor : beanPostProcessors) &#123; //Bean实例对象在初始化之前做一些自定义的处理操作 Object current = beanProcessor.postProcessBeforeInitialization(result, beanName,this); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125; //调用BeanPostProcessor 初始化调用实例之后的处理方法 public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws Exception &#123; Object result = existingBean; //遍历容器为所创建的Bean添加的所有BeanPostProcessor for (BeanPostProcessor beanProcessor : beanPostProcessors) &#123; //Bean实例对象在初始化之后做一些自定义的处理操作 Object current = beanProcessor.postProcessAfterInitialization(result, beanName,this); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125; //对字段进行依赖注入,只注入对象类型,基本类型未判断 private void populateBean(Object instance, BeanDefinition beanDefinition, Class&lt;?&gt; clazz) throws Exception&#123; Object autowiredBean; //加入正在创建的bean集合中，防止循环引用 singletonsCurrentlyInCreation.add(beanDefinition.getBeanClassName()); //获得所有的字段 Field[] fields = clazz.getDeclaredFields(); for (Field field : fields) &#123; //只对加了注解的字段进行依赖注入 if(!field.isAnnotationPresent(Autowired.class))&#123; continue;&#125; Autowired autowired = field.getAnnotation(Autowired.class); String autowiredBeanName = autowired.value().trim(); if(\"\".equals(autowiredBeanName))&#123; autowiredBeanName = field.getType().getName(); &#125; //访问私有变量 field.setAccessible(true); try &#123; //获取需要注入的实例 autowiredBean = this.singletonObjects.get(autowiredBeanName); //如果需要注入的实例还未创建,则创建 if(null == autowiredBean)&#123; //递归创建bean getBean(autowiredBeanName); &#125; field.set(instance,autowiredBean); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; //注入完成后删除 singletonsCurrentlyInCreation.remove(beanDefinition.getBeanClassName()); &#125;&#125; AbstractApplicationContext定义ApplicationContext的抽象类，其中有启动容器方法。 1234567891011121314151617181920212223242526272829package top.jinjinz.spring.context.support;import top.jinjinz.spring.beans.factory.BeanFactory;import top.jinjinz.spring.context.ApplicationContext;/** * ApplicationContexts顶层抽象类 * author:jinjin * Date:2019/4/14 3:35 */public abstract class AbstractApplicationContext implements ApplicationContext &#123; public void refresh() throws Exception&#123; BeanFactory beanFactory = obtainFreshBeanFactory(); &#125; protected BeanFactory obtainFreshBeanFactory() throws Exception&#123; //具体实现调用子类容器的refreshBeanFactory()方法 refreshBeanFactory(); BeanFactory beanFactory = getBeanFactory(); return beanFactory; &#125; protected abstract void refreshBeanFactory() throws Exception; public abstract BeanFactory getBeanFactory();&#125; PropertiesApplicationContext定义Properties配置文件的启动方式，扫描注解类并注册 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package top.jinjinz.spring.context.support;import top.jinjinz.spring.beans.factory.BeanFactory;import top.jinjinz.spring.beans.factory.config.BeanDefinition;import top.jinjinz.spring.beans.factory.config.BeanPostProcessor;import top.jinjinz.spring.beans.factory.support.BeanDefinitionRegistry;import top.jinjinz.spring.beans.factory.support.DefaultListableBeanFactory;import top.jinjinz.spring.context.annotation.AnnotatedBeanDefinitionReader;import java.io.File;import java.io.IOException;import java.io.InputStream;import java.net.URL;import java.util.*;/** * PropertiesApplication方式 * @author jinjin * @date 2019-04-15 */public class PropertiesApplicationContext extends AbstractApplicationContextimplements BeanDefinitionRegistry &#123; private Properties config = new Properties(); private final String SCAN_PACKAGE = \"scanPackage\"; private Set&lt;Class&lt;?&gt;&gt; annotatedClasses = new LinkedHashSet&lt;&gt;(); private DefaultListableBeanFactory beanFactory; public PropertiesApplicationContext(String... locations) throws Exception&#123; InputStream is = this.getClass().getClassLoader().getResourceAsStream( locations[0].replace(\"classpath:\",\"\")); try &#123; config.load(is); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(null != is)&#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; doScanner(config.getProperty(SCAN_PACKAGE)); refresh(); &#125; @Override protected void refreshBeanFactory() throws Exception&#123; DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); this.beanFactory = beanFactory; loadBeanDefinitions(beanFactory); &#125; @Override public BeanFactory getBeanFactory() &#123; return beanFactory; &#125; @Override public Object getBean(String beanName) throws Exception &#123; return this.beanFactory.getBean(beanName); &#125; @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws Exception&#123; this.beanFactory.registerBeanDefinition(beanName,beanDefinition); &#125; @Override public void removeBeanDefinition(String beanName) &#123; this.beanFactory.removeBeanDefinition(beanName); &#125; @Override public BeanDefinition getBeanDefinition(String beanName) &#123; return this.beanFactory.getBeanDefinition(beanName); &#125; @Override public boolean containsBeanDefinition(String beanName) &#123; return this.beanFactory.containsBeanDefinition(beanName); &#125; @Override public String[] getBeanDefinitionNames() &#123; return this.beanFactory.getBeanDefinitionNames(); &#125; @Override public int getBeanDefinitionCount() &#123; return this.beanFactory.getBeanDefinitionCount(); &#125; @Override public void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; this.beanFactory.addBeanPostProcessor(beanPostProcessor); &#125; private void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws Exception&#123; AnnotatedBeanDefinitionReader reader = new AnnotatedBeanDefinitionReader(beanFactory); if (!this.annotatedClasses.isEmpty()) &#123; reader.register(this.annotatedClasses.toArray(new Class&lt;?&gt;[0])); &#125; //将注册的bean进行初始化 String[] beanNames = beanFactory.getBeanDefinitionNames(); for (String beanName:beanNames) &#123; getBean(beanName); &#125; &#125; private void doScanner(String scanPackage) throws Exception &#123; URL url = this.getClass().getClassLoader().getResource( \"/\" + scanPackage.replaceAll(\"\\\\.\", \"/\")); if (null == url) &#123; return; &#125; File dir = new File(url.getFile()); File[] dirs = dir.listFiles(); if (null == dirs) &#123; return; &#125; //找出所有的文件名称,去除.class后缀 for (File file : dirs) &#123; //如果是文件夹则递归 if (file.isDirectory()) &#123; doScanner(scanPackage + \".\" + file.getName()); &#125; else &#123; Class&lt;?&gt; beanClass = Class.forName( scanPackage + \".\" + file.getName().replace(\".class\", \"\").trim()); if (!beanClass.isInterface()) &#123; this.annotatedClasses.add(beanClass); &#125; &#125; &#125; &#125;&#125; AbstractBeanDefinitionBeanDefinition的基本实现类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package top.jinjinz.spring.beans.factory.support;import top.jinjinz.spring.beans.factory.config.BeanDefinition;/** * BeanDefinition基本实现 * author:jinjin * Date:2019/4/13 23:27 */public abstract class AbstractBeanDefinition implements BeanDefinition&#123; private volatile String beanClass; private boolean lazyInit = false; private String factoryBeanName; protected AbstractBeanDefinition()&#123;&#125;; protected AbstractBeanDefinition(BeanDefinition original) &#123; setBeanClassName(original.getBeanClassName()); setLazyInit(original.isLazyInit()); setFactoryBeanName(original.getFactoryBeanName()); &#125; @Override public void setBeanClassName(String beanClassName) &#123; this.beanClass = beanClassName; &#125; @Override public String getBeanClassName() &#123; return beanClass; &#125; @Override public void setLazyInit(boolean lazyInit) &#123; this.lazyInit = lazyInit; &#125; @Override public boolean isLazyInit() &#123; return this.lazyInit; &#125; @Override public void setFactoryBeanName(String factoryBeanName) &#123; this.factoryBeanName = factoryBeanName; &#125; @Override public String getFactoryBeanName() &#123; return this.factoryBeanName; &#125;&#125; AbstractBeanDefinitionReaderBeanDefinitionReader基本实现 12345678910111213141516171819202122232425262728293031package top.jinjinz.spring.beans.factory.support;import java.io.IOException;/** * BeanDefinitionReader基本实现 * @author jinjin * @date 2019-04-15 */public abstract class AbstractBeanDefinitionReader implements BeanDefinitionReader&#123; private final BeanDefinitionRegistry registry; protected AbstractBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this.registry = registry; &#125; @Override public final BeanDefinitionRegistry getRegistry() &#123; return this.registry; &#125; @Override public int loadBeanDefinitions(String... locations) throws IOException &#123; int counter = 0; for (String location : locations) &#123; counter += loadBeanDefinitions(location); &#125; return counter; &#125;&#125; AnnotatedBeanDefinitionReader扫描注解类，注册 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package top.jinjinz.spring.context.annotation;import top.jinjinz.spring.aop.annotation.After;import top.jinjinz.spring.aop.annotation.AfterThrowing;import top.jinjinz.spring.aop.annotation.Aspect;import top.jinjinz.spring.aop.annotation.Before;import top.jinjinz.spring.aop.aspectj.AspectJAdvice;import top.jinjinz.spring.aop.autoproxy.AutoProxyCreator;import top.jinjinz.spring.beans.factory.annotation.AnnotatedBeanDefinition;import top.jinjinz.spring.beans.factory.annotation.Component;import top.jinjinz.spring.beans.factory.annotation.Controller;import top.jinjinz.spring.beans.factory.annotation.Service;import top.jinjinz.spring.beans.factory.config.BeanDefinition;import top.jinjinz.spring.beans.factory.config.BeanPostProcessor;import top.jinjinz.spring.beans.factory.support.BeanDefinitionRegistry;import java.lang.reflect.Method;import java.util.*;/** * 注解bean类的注册器 * @author jinjin * @date 2019-04-15 */public class AnnotatedBeanDefinitionReader &#123; private final BeanDefinitionRegistry registry; private Map&lt;String,List&lt;AspectJAdvice&gt;&gt; aspectMethods = new HashMap&lt;&gt;(); private List&lt;String&gt; patterns = new ArrayList&lt;&gt;(); public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this.registry = registry; &#125; public void register(Class&lt;?&gt;... annotatedClasses) throws Exception&#123; for (Class&lt;?&gt; annotatedClass : annotatedClasses) &#123; registerBean(annotatedClass); &#125; BeanPostProcessor autoProxyCreator = new AutoProxyCreator(aspectMethods,patterns); registry.addBeanPostProcessor(autoProxyCreator); &#125; public void registerBean(Class&lt;?&gt; annotatedClass) throws Exception&#123; //IOC容器中只注册加了指定注解的类 if(isRegister(annotatedClass))&#123; doRegisterBean(annotatedClass); parseBean(annotatedClass); &#125; &#125; //解析bean的其他注解信息并注册其功能 private void parseBean(Class&lt;?&gt; annotatedClass) &#123; //注册aop注解类 if(annotatedClass.isAnnotationPresent(Aspect.class))&#123; parseAspect(annotatedClass); &#125; &#125; //注册Aspect信息 private void parseAspect(Class&lt;?&gt; annotatedClass) &#123; List&lt;AspectJAdvice&gt; aspectJAdviceList; Method[] methods=annotatedClass.getMethods(); String pointCut = \"\"; for (Method method:methods) &#123; if(method.isAnnotationPresent(Before.class))&#123; pointCut = method.getAnnotation(Before.class).value(); &#125; if(method.isAnnotationPresent(After.class))&#123; pointCut = method.getAnnotation(After.class).value(); &#125; if(method.isAnnotationPresent(AfterThrowing.class))&#123; pointCut = method.getAnnotation(AfterThrowing.class).pointcut(); &#125; if(\"\".equals(pointCut))&#123; continue; &#125; if(!patterns.contains(pointCut))&#123; patterns.add(pointCut); &#125; aspectJAdviceList=aspectMethods.get(pointCut); if(null == aspectJAdviceList)&#123; aspectJAdviceList = new ArrayList&lt;&gt;(); &#125; aspectJAdviceList.add(new AspectJAdvice(method,annotatedClass.getName())); aspectMethods.put(pointCut,aspectJAdviceList); &#125; &#125; private boolean isRegister(Class&lt;?&gt; annotatedClass)&#123; return annotatedClass.isAnnotationPresent(Component.class)|| annotatedClass.isAnnotationPresent(Controller.class)|| annotatedClass.isAnnotationPresent(Service.class); &#125; //注册bean信息 private &lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass) throws Exception&#123; registry.registerBeanDefinition(annotatedClass.getName(),doCreateBeanDefinition( toLowerFirstCase( annotatedClass.getSimpleName()),annotatedClass.getName())); Class&lt;?&gt; [] interfaces = annotatedClass.getInterfaces(); for (Class&lt;?&gt; i : interfaces) &#123; registry.registerBeanDefinition( i.getName(),doCreateBeanDefinition(i.getName(),annotatedClass.getName())); &#125; &#125; private BeanDefinition doCreateBeanDefinition(String factoryBeanName, String beanClassName)&#123; BeanDefinition beanDefinition = new AnnotatedBeanDefinition(); beanDefinition.setBeanClassName(beanClassName); beanDefinition.setFactoryBeanName(factoryBeanName); return beanDefinition; &#125; private String toLowerFirstCase(String simpleName) &#123; char [] chars = simpleName.toCharArray(); chars[0] += 32; return String.valueOf(chars); &#125;&#125; spring-webmvc基于servlet实现webmvc 接口定义HandlerAdapter执行方法并动态匹配参数 12345678910111213141516package top.jinjinz.spring.web.servlet;import top.jinjinz.spring.web.servlet.method.HandlerMethod;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * 执行Handler的方法,动态匹配参数 * @author jinjin * @date 2019-04-17 */public interface HandlerAdapter &#123; ModelAndView handle(HttpServletRequest request, HttpServletResponse response, HandlerMethod handler) throws Exception;&#125; HandlerMappingHandler映射处理器 123456789101112131415package top.jinjinz.spring.web.servlet;import top.jinjinz.spring.web.servlet.method.HandlerMethod;import javax.servlet.http.HttpServletRequest;/** * Handler映射处理器 * @author jinjin * @date 2019-04-17 */public interface HandlerMapping &#123; HandlerMethod getHandler(HttpServletRequest request) throws Exception;&#125; 功能实现DispatcherServletServlet的启动类，作为启动入口实现核心逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package top.jinjinz.spring.web.servlet;import top.jinjinz.spring.context.ApplicationContext;import top.jinjinz.spring.context.support.PropertiesApplicationContext;import top.jinjinz.spring.web.servlet.method.HandlerMethod;import top.jinjinz.spring.web.servlet.method.HandlerMethodAdapter;import top.jinjinz.spring.web.servlet.method.HandlerMethodMapping;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.*;/** * 启动入口 * @author jinjin * @date 2019-04-13 */public class DispatcherServlet extends HttpServlet &#123; private HandlerMapping handlerMapping; private HandlerAdapter handlerAdapter; public DispatcherServlet()&#123; super(); &#125; /** * 初始化，加载配置文件 */ public void init(ServletConfig config) throws ServletException &#123; try &#123; PropertiesApplicationContext context = new PropertiesApplicationContext(\"application.properties\"); initStrategies(context); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; //提示信息 System.out.println(\"mvc is init\"); &#125; protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; this.doPost(req, resp); &#125; /** * 执行业务处理 */ protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; try&#123; //匹配对应方法 doDispatch(req,resp); &#125;catch(Exception e)&#123; resp.getWriter().write(\"500 Exception,Details:\\r\\n\" + Arrays.toString(e.getStackTrace()).replaceAll(\"\\\\[|\\\\]\", \"\") .replaceAll(\",\\\\s\", \"\\r\\n\")); &#125; &#125; private void doDispatch(HttpServletRequest req,HttpServletResponse resp) throws Exception&#123; HandlerMethod handler = handlerMapping.getHandler(req); if(null == handler)&#123; resp.getWriter().write(\"404 Not Found\"); return; &#125; ModelAndView mv = handlerAdapter.handle(req,resp,handler); //resp.getWriter().write(mv.getModel().values().toString()); &#125; //初始化策略 private void initStrategies(ApplicationContext context) &#123; //多文件上传的组件 initMultipartResolver(context); //初始化本地语言环境 initLocaleResolver(context); //初始化模板处理器 initThemeResolver(context); //初始化Handler映射处理器 initHandlerMappings(context); //初始化参数适配器 initHandlerAdapters(context); //初始化异常拦截器 initHandlerExceptionResolvers(context); //初始化视图预处理器 initRequestToViewNameTranslator(context); //初始化视图转换器 initViewResolvers(context); //FlashMap管理器 initFlashMapManager(context); &#125; private void initFlashMapManager(ApplicationContext context) &#123; &#125; private void initViewResolvers(ApplicationContext context) &#123; &#125; private void initRequestToViewNameTranslator(ApplicationContext context) &#123; &#125; private void initHandlerExceptionResolvers(ApplicationContext context) &#123; &#125; private void initHandlerAdapters(ApplicationContext context) &#123; this.handlerAdapter = new HandlerMethodAdapter(); &#125; private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMapping = new HandlerMethodMapping(context); &#125; private void initThemeResolver(ApplicationContext context) &#123; &#125; private void initLocaleResolver(ApplicationContext context) &#123; &#125; private void initMultipartResolver(ApplicationContext context) &#123; &#125;&#125; HandlerMethod封装Handler的信息 12345678910111213141516171819202122232425262728package top.jinjinz.spring.web.servlet.method;import java.lang.reflect.Method;/** * 封装Handler的信息 * @author jinjin * @date 2019-04-17 */public class HandlerMethod &#123; private final Object bean; private final Method method; public HandlerMethod(Object bean, Method method) &#123; this.bean = bean; this.method = method; &#125; public Object getBean() &#123; return bean; &#125; public Method getMethod() &#123; return method; &#125;&#125; HandlerMethodAdapterHandlerAdapter实现类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package top.jinjinz.spring.web.servlet.method;import top.jinjinz.spring.beans.factory.annotation.RequestParam;import top.jinjinz.spring.web.servlet.HandlerAdapter;import top.jinjinz.spring.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.lang.annotation.Annotation;import java.util.Arrays;import java.util.HashMap;import java.util.Map;/** * HandlerAdapter实现类 * @author jinjin * @date 2019-04-17 */public class HandlerMethodAdapter implements HandlerAdapter &#123; @Override public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, HandlerMethod handler) throws Exception &#123; //把方法的形参列表和request的参数列表所在顺序进行对应 Map&lt;String,Integer&gt; paramIndexMapping = new HashMap&lt;&gt;(); //提取方法中加了注解的参数 Annotation[] [] pa = handler.getMethod().getParameterAnnotations(); for (int i = 0; i &lt; pa.length ; i ++) &#123; for(Annotation a : pa[i])&#123; if(a instanceof RequestParam)&#123; String paramName = ((RequestParam) a).value(); if(\"\".equals(paramName.trim()))&#123; //todo 参数没有加注解则反射获取参数名称 &#125;else &#123; paramIndexMapping.put(paramName, i); &#125; &#125; &#125; &#125; //提取方法中的request和response参数 Class&lt;?&gt; [] paramsTypes = handler.getMethod().getParameterTypes(); for (int i = 0; i &lt; paramsTypes.length ; i ++) &#123; Class&lt;?&gt; type = paramsTypes[i]; if(type == HttpServletRequest.class || type == HttpServletResponse.class)&#123; paramIndexMapping.put(type.getName(),i); &#125; &#125; //获得方法的形参列表 Map&lt;String,String[]&gt; params = request.getParameterMap(); //实参列表 Object [] paramValues = new Object[paramsTypes.length]; for (Map.Entry&lt;String, String[]&gt; parm : params.entrySet()) &#123; String value = Arrays.toString(parm.getValue()) .replaceAll(\"\\\\[|\\\\]\",\"\").replaceAll(\"\\\\s\",\",\"); if(!paramIndexMapping.containsKey(parm.getKey()))&#123;continue;&#125; int index = paramIndexMapping.get(parm.getKey()); paramValues[index] = caseStringValue(value,paramsTypes[index]); &#125; if(paramIndexMapping.containsKey(HttpServletRequest.class.getName())) &#123; int reqIndex = paramIndexMapping.get(HttpServletRequest.class.getName()); paramValues[reqIndex] = request; &#125; if(paramIndexMapping.containsKey(HttpServletResponse.class.getName())) &#123; int respIndex = paramIndexMapping.get(HttpServletResponse.class.getName()); paramValues[respIndex] = response; &#125; Object result = handler.getMethod().invoke(handler.getBean(),paramValues); if(result == null || result instanceof Void)&#123; return null; &#125; boolean isModelAndView = handler.getMethod().getReturnType() == ModelAndView.class; if(isModelAndView)&#123; return (ModelAndView) result; &#125; return null; &#125; private Object caseStringValue(String value, Class&lt;?&gt; paramsType) &#123; if(String.class == paramsType)&#123; return value; &#125; //如果是int if(Integer.class == paramsType)&#123; return Integer.valueOf(value); &#125; else if(Double.class == paramsType)&#123; return Double.valueOf(value); &#125; return value; &#125;&#125; HandlerMethodMappingHandlerMapping的实现类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package top.jinjinz.spring.web.servlet.method;import top.jinjinz.spring.aop.annotation.AopProxyUtils;import top.jinjinz.spring.beans.factory.annotation.Controller;import top.jinjinz.spring.beans.factory.annotation.RequestMapping;import top.jinjinz.spring.context.ApplicationContext;import top.jinjinz.spring.web.servlet.HandlerMapping;import javax.servlet.http.HttpServletRequest;import java.lang.reflect.Method;import java.util.*;/** * HandlerMapping的实现类 * @author jinjin * @date 2019-04-17 */public class HandlerMethodMapping implements HandlerMapping &#123; private final MappingRegistry mappingRegistry = new MappingRegistry(); public HandlerMethodMapping(ApplicationContext context) &#123; initHandlerMethod(context); &#125; @Override public final HandlerMethod getHandler(HttpServletRequest request) throws Exception &#123; String url = request.getRequestURI(); String contextPath = request.getContextPath(); url = url.replace(contextPath, \"\").replaceAll(\"/+\", \"/\"); return this.mappingRegistry.getHandlerMethod(url); &#125; private void initHandlerMethod(ApplicationContext context) &#123; String [] beanNames = context.getBeanDefinitionNames(); try &#123; for (String beanName : beanNames) &#123; Object bean = context.getBean(beanName); Object target = AopProxyUtils.getTargetObject(bean); Class&lt;?&gt; clazz = target.getClass(); //只对加了@Controller注解的类进行初始化 if(!clazz.isAnnotationPresent(Controller.class))&#123; continue; &#125; String baseUrl = \"\"; //获取Controller的url配置 if(clazz.isAnnotationPresent(RequestMapping.class))&#123; RequestMapping requestMapping = clazz.getAnnotation(RequestMapping.class); baseUrl = requestMapping.value(); &#125; //获取Method的url配置 Method[] methods = clazz.getMethods(); for (Method method : methods) &#123; //没有加RequestMapping注解的直接忽略 if(!method.isAnnotationPresent(RequestMapping.class))&#123; continue; &#125; //映射URL RequestMapping requestMapping = method.getAnnotation(RequestMapping.class); // /demo/query 字符串处理 // (//demo//query) String regex = (\"/\" + baseUrl + \"/\" + requestMapping.value(). replaceAll(\"\\\\*\",\".*\")).replaceAll(\"/+\", \"/\"); this.mappingRegistry.register(regex,target,method); System.out.println(\"Mapped \" + regex + \",\" + method); &#125; &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; private HandlerMethod createHandlerMethod(Object handler, Method method) &#123; return new HandlerMethod(handler, method); &#125; class MappingRegistry &#123; private final Map&lt;String, MappingRegistration&lt;String&gt;&gt; registry = new HashMap&lt;&gt;(); private final Map&lt;String, HandlerMethod&gt; mappingLookup = new LinkedHashMap&lt;&gt;(); public Map&lt;String, HandlerMethod&gt; getMappings() &#123; return this.mappingLookup; &#125; public HandlerMethod getHandlerMethod(String mappings) &#123; return this.mappingLookup.get(mappings); &#125; public void register(String mapping, Object handler, Method method) &#123; HandlerMethod handlerMethod = createHandlerMethod(handler, method); this.mappingLookup.put(mapping, handlerMethod); &#125; &#125; private static class MappingRegistration&lt;T&gt; &#123; private final T mapping; private final HandlerMethod handlerMethod; public MappingRegistration(T mapping, HandlerMethod handlerMethod) &#123; this.mapping = mapping; this.handlerMethod = handlerMethod; &#125; public T getMapping() &#123; return this.mapping; &#125; public HandlerMethod getHandlerMethod() &#123; return this.handlerMethod; &#125; &#125;&#125; 功能测试spring-testservice配置Service 12345678910package top.jinjinz.spring.test.service; /** * Demo Service * @author jinjin * @date 2019-03-25 */public interface DemoService &#123; String hello(String name);&#125; 1234567891011121314151617181920package top.jinjinz.spring.test.service.impl;import top.jinjinz.spring.beans.factory.annotation.Service;import top.jinjinz.spring.test.service.DemoService;/** * Demo Service实现 * @author jinjin * @date 2019-03-25 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String hello(String name) &#123; String hello = \"hello \"+name; System.out.println(\"执行方法返回：\"+hello); return hello; &#125;&#125; controller配置Controller 123456789101112131415161718192021222324252627package top.jinjinz.spring.test.controller;import top.jinjinz.spring.beans.factory.annotation.Autowired;import top.jinjinz.spring.beans.factory.annotation.Controller;import top.jinjinz.spring.beans.factory.annotation.RequestMapping;import top.jinjinz.spring.beans.factory.annotation.RequestParam;import top.jinjinz.spring.test.service.DemoService;import javax.servlet.http.HttpServletResponse;/** * Demo控制器 * @author jinjin * @date 2019-03-25 */@Controller@RequestMapping(\"/demo\")public class DemoController &#123; @Autowired private DemoService demoService; @RequestMapping(\"/hello\") public void hello(@RequestParam(\"name\") String name, HttpServletResponse resp) throws Exception&#123; resp.getWriter().write(demoService.hello(name)); &#125;&#125; aspect配置切面 123456789101112131415161718192021222324252627282930313233package top.jinjinz.spring.test.aspect;import top.jinjinz.spring.aop.annotation.After; import top.jinjinz.spring.aop.annotation.Aspect;import top.jinjinz.spring.aop.annotation.Before;import top.jinjinz.spring.aop.intercept.Joinpoint;import top.jinjinz.spring.beans.factory.annotation.Component;import java.util.Arrays;/** * 日志切面 * @author jinjin * @date 2019-04-18 */@Aspect@Componentpublic class LogAspect &#123; //使用正则 @Before(\"public .* top.jinjinz.spring.test.service..*Service..*(.*)\") //在调用一个方法之前，执行before方法 public void before(Joinpoint joinPoint)&#123; System.out.println(\"执行方法前\"); &#125; @After(\"public .* top.jinjinz.spring.test.service..*Service..*(.*)\") //在调用一个方法之后，执行after方法 public void after(Joinpoint joinPoint)&#123; System.out.println(\"执行方法后\"); &#125;&#125; application.propertiesapplication.properties作为配置文件，配置所需要的属性 1scanPackage=top.jinjinz.spring web.xml配置自定义Servlet DispatcherServlet及设置匹配请求 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:javaee=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\" version=\"2.4\"&gt; &lt;display-name&gt;Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;servlet-class&gt;top.jinjinz.spring.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 测试效果","tags":[{"name":"Spring","slug":"Spring","permalink":"https://jinjinz.top/tags/Spring/"}]},{"title":"Innodb中的锁机制及MVCC原理","date":"2019-03-29T09:31:56.000Z","path":"mysql/mysql-innodb.html","text":"Innodb引擎的官方文档地址：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html 了解Innodb的锁和MVCC前，我们应该先了解MySQL支持的存储引擎及事务，以及各个事务隔离级别的区别 存储引擎MySQL的存储引擎是插件式的体系结构，每个存储引擎都有其各自的特点，我们可以根据具体的应用需求使用不同的存储引擎表，现在最常用的存储引擎是Innodb。 可以使用show engines;命令查询存储引擎 MySQL中有很多存储引擎，数据库中的每一个表都可以使用不同的存储引擎。 Support表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎 。 MEMORY引擎Memory存储引擎的数据存储在内存中，但是服务重启或发生崩溃时数据会丢失，该引擎适合用在临时表中存储临时数据。 特点： Memory存储引擎支持hash索引和B+树索引，默认使用hash索引。 存储在Memory数据表里的数据必须使用的是长度不变的格式，所以BLOB和TEXT这样的长度可变的数据类型是不能使用的，VARCHAR在MySQL内部当做长度固定不变的CHAR类型，所以可以使用。 ARCHIVE引擎Archive是归档的意思，在归档之后仅仅支持最基本的插入和查询两种功能。Archive拥有很好的压缩机制，它使用zlib算法将数据行压缩后进行存储，在记录被请求时会实时压缩，所以在使用大量的数据采集时可以使用，比较适合用来存储日志信息，提供高速的插入和压缩功能。 特点： ARCHIVE引擎只支持insert和select操作，不支持update和delete操作。 ARCHIVE引擎的数据文件比较小，占用的磁盘空间更少。 MyISAM引擎MyISAM存储引擎不支持事务，也不支持外键；访问速度快，对事务完整性没有要求或者以查询、插入为主的应用可以使用这个引擎来创建表。每个MyISAM在磁盘上存储成表定义文件、索引文件和数据文件3个文件 特点： MyISAM引擎中存储表的数据和索引需要分开存储。 MyISAM中不支持事务以及行锁，只能使用表级锁，所以并发性能较低。 InnoDB引擎Mysql5.5及以后版本的默认存储引擎，innoDB存储引擎支持事务且引入了行级锁和外键约束等功能。 特点： InnoDB引擎在存储表时会以聚集索引的形式进行数据存储，也就是索引和数据文件在同一个文件上。 InnoDB支持行锁，采用MVCC支持高并发，并且支持事务。 事务InnoDB与MyISAM的最大不同有两点：一是支持事务；二是采用了行级锁。行级锁与表级锁本来就有许多不同之处，另外，事务的引入也带来了一些新问题。下面我们先介绍一点背景知识，然后详细讨论InnoDB的锁问题。 事务是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；是一组不可再分割的工作单元 银行的账户转账就是一个典型的事务例子，一个账户的扣除余额操作和一个账号的增加余额操作是两条sql语句，但是必须保证同时成功或者同时失败。 事务ACID特性 原子性（Atomicity）最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚 一致性（Consistency）事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致 隔离性（Isolation）一个事务所操作的数据在提交之前，对其他事务不可见 持久性（Durability）事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失 事务日志InnoDB的事务日志有两种，分别是redo log和undo log。 redo log是防止发生故障时有脏页未写入磁盘，保证了事务的持久性； undo log是回滚日志，提供回滚操作，保证了事务的一致性。 redo log是物理日志，记录的是数据页的物理修改；undo log是逻辑日志，根据每行记录进行记录。 Redo Logredo log有两部分，一个是内存中的日志缓冲(redo log buffer)，第二是磁盘上的重做日志文件(redo log file)。 InnoDB在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的重做日志文件 (redo log file) 和回滚日志文件 (undo log file) 中进行持久化。 在将内存中的日志缓冲区的内容写到磁盘上的日志文件时，首先会将用户空间中的缓存区日志复制到操作系统的缓冲区中，之后调用操作系统的fsync()操作，操作系统才会将缓冲区中的日志写到磁盘中的文件中，过程如下： 我们可以通过变量 innodb_flush_log_at_trx_commit 的值来决定在提交事务时何时将日志文件持久化到磁盘中。该变量有3种值：0、1、2，默认为1。 设置为0时，事务提交时不写入os buffer，而是每秒钟写入os buffer并调用fsync()写入log file。也就是说当系统崩溃时会丢失1秒的数据。 设置为1时，事务每次提交时都会将日志缓冲区中的日志写入os buffer并调用fsync()写入日志文件。这样即使系统崩溃时也不会丢失数据，但是每次提交都需要写入磁盘，IO的性能较差。 设置为2时，事务每次提交时都会将日志缓冲区中的日志写入os buffer，然后是每秒调用fsync()将os buffer中的日志写入到磁盘中的日志文件中 。 Undo Log对数据进行修改时，需要记录redo log 和 undo log，redo log 保证了事务提交后数据的持久性，而 undo log 保证了如果事务失败，则可以借助undo log进行回滚操作。 当删除一条记录时，undo log 中会记录删除前的数据以保证回滚时的数据一致性，执行修改时也一样，回滚日志中会记录更改前的数据。 Purge线程当事务提交的时候，InnoDB不会立即删除undo log，因为InnoDB支持MVCC，所以后续还可能会用到undo log的记录，在默认的隔离级别repeatable read下，事务读取的都是开启事务时的最新提交行版本，只要该事务还没有结束，该行版本就不能被删除。 但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，通过purge后台线程来删除。 并发事务相对于串行处理事务，并发事务可以提升数据库资源的利用率，但并发事务处理也会带来一些问题，主要包括以下几种情况。 脏读 在事务A对数据修改后但未提交时，此时事务B读取了事务A修改后的数据并产生后续处理，这种现象被叫做脏读，因为事务A的记录还没有提交，有可能会进行回滚或其他操作。 不可重复读 一个事务读取的数据在某个时间后再次读取，但是读取出的数据却已经发生了改变，出现了不一致现象，这种现象被称为不可重复读。 幻读 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象被称为幻读。 隔离级别为了解决并发事务时会产生的问题，数据库需要提供事务隔离机制来解决，数据库实现事务隔离的方式，基本上可分为以下两种： 第一种是在读取数据时加锁，其他事务就不能对数据进行修改了。 第二种为不加锁，生成一个数据的不同时间点的数据快照，使用快照实现不同事务的读取。这种技术叫做数据多版本并发控制（MultiVersion Concurrency Control，简称MVCC）。 数据库的事务隔离在一定程度上牺牲了并发的性能，但是不同的应用程序可能对于事务的隔离程度要求并不是太严格，所以在SQL92标准中定义了4个事务隔离级别，根据隔离程度允许出现的副作用不同，应用可以根据自己的需求来选择事务的隔离级别。 Read Uncommitted（未提交读） 事务未提交时的数据对其他事务也是可见的，这是最低的隔离级别，允许脏读，不可重复读及幻读。 Read Committed（已提交读，也称不可重复读） 一个事务开始之后，只能看到提交的事务所做的修改，解决了脏读问题，但是会出现不可重复读和幻读。 Repeatable Read (可重复读) 在同一个事务中多次读取同样的数据结果是一样的，解决了不可重复读问题，这种隔离级别未定义解决幻读的问题，在innodb中通过临键锁解决了幻读问题。 Serializable（串行化） 最高的隔离级别，强制事务的串行执行。 锁锁用于管理不同事务对共享资源的并发访问，在读取数据前，对其加锁，阻止其他事务对数据进行修改。 表锁的并发性能相对于行锁较低，且行锁的锁定粒度和冲突概率也比表锁更小。 共享锁和排他锁InnoDB中实现的行锁有两种类型，共享锁和排他锁。 共享锁 (shared lock): 共享锁简称s锁，持有该行的s锁的事务允许读取行数据，多个事务对于同一行数据可以共享锁，但是只有读取数据的权限，没有对数据进行修改的权限。 排他锁 (exclusive lock): 排他锁简称x锁，持有该行的x锁的事务允许更新或删除行数据，如果一个事务获取了一个数据行的x锁，其他事务必须等待锁的释放。 意向共享锁和意向排它锁InnoDB中可以支持多种粒度的锁定，允许表锁和行锁共存，意向锁就是表锁，有两种类型，意向共享锁和意向排它锁。意向锁的意思为稍后对表中的数据行所需的锁类型，可能是共享锁或排他锁。 意向共享锁 (intention shared lock)： 意向共享锁简称is锁，表示事务准备获取某些数据行的共享锁，在获取表中数据行的共享锁之前，必须首先获得表上的意向共享锁。 意向排它锁 (intention exclusive lock): 意向排它锁简称ix锁，表示事务准备获取某些数据行的排他锁，在获取表中数据行的排他锁之前，必须首先获得表上的意向排他锁。 当事务想要获取数据行上的锁时，需要先获取意向锁，如果锁定请求与现有锁定冲突，则无法授予锁。 记录锁记录锁 (record lock): 记录锁就就是对索引记录的锁定。即使表中没有创建索引，InnoDB也会创建一个隐藏的聚簇索引并且使用此索引来进行记录锁定。记录锁就是所谓的行锁。 间隙锁间隙锁 (gap lock)： 间隙锁就是锁定索引记录之间的间隙，或者锁定在第一个索引记录之前或最后一个索引记录之后的间隙。 以下sql语句将阻止其他事务将值15插入列column1中，因为该范围中之间的间隙已经被锁定。 1select column1 from table_name where column1 &gt; 10 and column1 &lt; 20 for update 假设表中column1列的索引包含值10,13,18,20，那么该列索引中的间隙如下： 需要注意的是，锁定的间隙可能会跨越多个索引值，也可能为空。间隙锁只被用于事务级别为Repeatable Read中。 Next-Key锁next-key lock ： next-key锁是锁定索引记录中的记录及锁定索引记录之间的间隙，也就是记录锁和间隙锁的组合。 Innodb执行行锁的锁定过程是，首先扫描表的索引，在满足条件的索引记录上设置共享锁或排他锁，这样行锁实际上就是锁定索引上的记录。 锁定索引上的下一个索引同样会影响该索引记录之前的间隙，也就是说next-key锁是锁定索引记录中的记录加上锁定索引记录之前的间隙。 假设表中column1列的索引包含值10,13,18,20，那么此索引的next-key锁包括以下几个区间，左开右闭。 对于第一个区间，锁定了索引中最小值之前的间隙，对于最后一个索引则锁定了索引中最大值之后的间隙。 因为默认情况下InnoDB使用的隔离级别为REPEATABLE READ，而在这种隔离级别下，InnoDB使用Next-Key锁阻止了幻读现象。 MVCCMVCC：Multiversion concurrency control (多版本并发控制) Innodb的多版本并发控制允许在数据库事务在Repeatable-Read的隔离级别下时，事务执行一致性的读取操作。其他事务在进行修改行时，其他事务可以不用获取该行的锁，并可以直接查看该行更新前的值。 Innodb的隐藏列Innodb在内部为数据库中存储的每一行添加了三个隐藏列。 列名 作用 DB_TRX_ID 插入或更新的事务id，删除在内部被视为更新，并设置删除标记位 DB_ROLL_PTR undo log指针，指向对应记录当前的undo log DB_ROW_ID 行ID，用来生成默认聚集索引 MVCC实现Innodb保存了已经被更改的数据行的旧版本信息，以支持并发和回滚等事务性的功能，这些信息保存在undo log中，Innodb使用undo log中的信息构建数据行的早期版本实现一致读取。 当事务1执行insert table_name(id,col1,col2,col3) value(10,1,2,3,4)时，数据行如下： 当事务2修改数据时，DB_TRX_ID记录修改数据的事务id，如果是删除数据的操作，则设置删除标识，最终的删除操作由purge线程完成。同时，purge线程会查询比当前最老的事务id还早的undo log并删除它们。 Innodb的可见性判断可见性比较的方法 并不是直接使用当前的事务id与表中各个数据行上的事务id去比较。 在每个事务开始时，会将当前系统中的所有活跃事务拷贝到一个列表中(read view)，根据read view最早的一个事务id和最晚的一个事务id来做比较；这样就能确保在当前事务之前没有提交的事务及后续启动事务的变更在当前的事务中是看不到的。 当然，当前事务自身的变更还是需要看到的。 可见性判断的流程 当开始一个事务时，把当前系统中活动的事务id都拷贝到一个列表中，这个列表中最早的活动事务id为tmin，最晚的活动事务id为tmax。 当读到一行时，该行上的当前事务id为tid，当前数据行是否可见的逻辑见下图： 如果事务需要获取一个数据行的数据，那么首先获取到数据行上的最后更新事务id，如果数据行上的更新事务id在活跃事务列表中小于最早的活动事务id，则可以直接获取该数据行的数据。 如果数据行上的更新事务id并不小于最早的活动事务id，也不大于最晚的活动事务id，但是不在活跃事务列表中，则也可以直接获取该数据行的数据。 如果数据行上的更新事务id大于最晚的活动事务id或者还在活跃事务列表中，则从undo log中取出对应的最新数据行，事务重新进行判断是否可以获取该数据行的数据。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jinjinz.top/tags/MySQL/"}]},{"title":"MySQL中的索引认识及优化","date":"2019-03-06T08:48:55.000Z","path":"mysql/mysql-index.html","text":"什么是索引？ 索引是用于快速查询数据的数据结构。通过索引去查找我们需要的数据，在数据量比较大时，性能会大大提升；但是错误的创建索引并不会提升查询的效率，所以我们需要正确的认识索引以及用正确的形式创建索引。 索引结构B树和B+树是目前的数据库应用中最常用、有效的索引结构。因为数据库中的数据一般保存在磁盘中，而IO操作是一个极其消耗时间的操作，所以我们需要通过B树或B+树进行优化，减少IO次数来提高效率。 在数据库中，可以根据B类树的特点，构建一个多阶的B树或B+树，其高度一般在2到3层，这样的话，对于查找某一个节点中关键字的值时，最多只需要2到3次IO。 B树B树的添加删除效果可以在 B树的演示网站 上查看 B树是一种平衡树数据结构，它的查找效率很高，所以通常会作为数据库的索引结构使用，它进行搜索的时间复杂度是 O(log n) 。 在一个 m 阶的B树中，它可以具有 m-1 数量的 key ，阶数表示了一个节点最多拥有的子节点数量。B树的每个内部节点包含的 key 用作分隔其子树的分离值。 下图是 key 值为 1 到 14 组成的一个3阶的B树： 上图中的数字即为节点中的 key ，每个key对应一个data，在mysql中，data就表示了这个 key 对应的数据在硬盘上的地址。 B+树B+树的添加删除效果可以在 B+树的演示网站 上查看 B+树是B树的一个变种，在B+树中，只有叶子节点保存了数据信息，其他节点仅包含了key信息，且叶子节点中包含了指向下一个叶子节点的指针来加速顺序访问。 下图是 key 值为 1 到 14 组成的一个4阶B+树： 一般索引也是存储在磁盘上的，所以索引的查找过程也会产生磁盘的IO消耗；而索引要尽量减少查找过程中磁盘IO的存取次数。 因为B+树的数据信息只存储在叶子节点，所以同样大小的磁盘页与B树相比存储的关键字变得更多，相应的也会减少IO次数。一般而言，每个节点会设置为一页大小，也就是一次IO读取，所以使用关键字查找时，B树的IO次数会多于B+树。 并且B树的查找性能并不稳定，B树需要查找的数据可能在根节点，也可能在叶子节点；而B+树的查询必须查找到叶子节点，所以每次的查找都是稳定的，且因为叶子节点的数据有指向下一个叶子节点的指针，所以在范围查询时只需要遍历叶子节点即可。 而对于关系型数据库来讲，范围查询的使用也是比较关键的，所以MySQL采用了B+树作为索引结构，而且在B+树中，查询的性能更加稳定，因为每次查询都必须到叶子节点。 索引实现索引的实现因存储引擎的不同，实现的方式也不同，下面只介绍B+树在最常用的 Innodb 引擎中的体现方式。 Innodb 存储引擎在innodb的表中，有两种索引类型，聚簇索引和辅助索引，两种索引的内部实现都是B+树，在聚簇索引中，聚簇索引会以表的主键作为索引的键，且数据行信息保存在叶子节点中。 假设我们现在有主键为id的一张用户表，数据如下： id name age 101 zhangsan 18 102 lisi 20 103 wangwu 22 104 zhaoliu 21 那么使用主键列id构建的聚簇索引如下： 除了聚簇索引之外的索引被称为辅助索引，辅助索引的键为其指定的列，在索引中的叶子节点数据为该行记录的主键值，根据此主键值再去聚簇索引中根据主键查询到对应的行。 使用 name 列构建的辅助索引如下： 辅助索引的存在并不会影响聚簇索引，一个表中虽然只能有一个聚簇索引，但对辅助索引没有限制；当通过辅助索引来查询数据时，会先通过辅助索引的叶子节点获取指向聚簇索引的主键，然后通过聚簇索引来找到一个完整的行记录。 也就是说，如果我们需要在上例数据中，通过name索引查找 “lisi” 的行记录，那么需要先对辅助索引遍历两次找到指定的主键，然后根据主键再去聚簇索引中进行2次查找，因此一共需要进行4次逻辑IO操作l来访问最终的数据页。 在字符串列中，辅助索引也可以创建仅使用列的前几个字符的索引，这样创建的索引可以使索引文件更小，在创建辅助索引时可以指定索引的前缀长度。 索引使用策略如果我们在表中没有创建索引，MySQL就必须从数据的第一行开始进行全表的扫描以查找到相关记录。表的数据越大，查找的成本也就越高；如果表中有相关的索引，那么MySQL就可以快速的定位到需要查找的数据，而不需要进行全表的扫描。 但是索引也不是在所有的查询条件下出现的列都需要添加，对于添加索引而言，还是有几个需要注意的关键点的。 高选择性使用索引的其中一个关键点就是，索引对于列的选择而言必须是具有高选择性的，例如对于性别字段，它的取值内容是固定的，或者说取值范围很小，即大部分是重复的数据，所以这种数据内容是低选择性的。 对于索引而言，如果需要查询的值在数据中能匹配大量的行数据，那么使用索引的效率是比较低下的；只有在索引匹配少量的数据时，索引才能高效的查询数据。 相反，如果某个列的数据大部分不会重复，例如姓名字段，则使用B+树索引比较合适，因此，在对一个列建立索引时，需要考虑该列的选择性。 索引选择性的计算公式是基数除以数据总行数，例如对于性别字段，假如表中有一万行数据，其中五千是男，五千是女，则基数为男和女，也就是 2/10000 ，最终计算出的选择性为 0.0002 ；而对于姓名字段，可能一万行数据中没有重复的，那基数就为 10000 /10000 ，选择性为 1，则从选择性方面而言，非常适合建立索引。 当选择性越大，则建立的索引价值也就越大。 条件匹配当在列上建立了索引后，在 where 条件中与索引中的列进行匹配，就可以加速查询，例如前面提到的用户表，如果建立了 name 列及 age 列的两个辅助索引，那么我们在条件查询中可以对添加了索引的列进行全值匹配、前缀匹配或者范围匹配。 以下是 sql 查询语句的示例 123select * from user where name = 'zhangsan' select * from user where name LIKE 'zha%' select * from user where age &gt; 18 and age &lt; 22 联合索引联合索引是指在多个列上建立索引，辅助索引中，不仅仅只能用一列创建索引，还可以创建多列的联合索引，联合索引中最多可以包含16列。 对于多列的索引，我们在条件查询中可以用到第一列，前两列及前三列等等，只要我们在条件查询中正确的指定联合索引中的列，则联合索引就可以加速查询。 例如对于用户表，我们建立了一个index(name,age)的联合索引，那么就可以查询 name 列和 age 列的组合条件，也可以仅指定 name 列的查询。 联合索引的内部结构其实还是B+树，但是其关键字并不是单独的一列的值了，而是多个列组合的值，例如对于上例中的用户表新建一个联合索引 index(name,age)，那么其内部结构如下： 因此，index(name,age)这个联合索引适用于如下 sql 查询： 123select * from user where name = 'zhangsan'select * from user where name = 'zhangsan' and age = 18select * from user where name = 'zhangsan' and age &gt; 18 and age &lt; 22 但是，这个联合索引并不能用于以下的 sql 查询 12select * from user where age = 18select * from user where name = 'zhangsan' or age = 18 所以，在一个查询中如果想要使用一个联合索引来加速查询，在条件匹配中必须符合这个联合索引的最左前缀，例如我们创建了一个 index(column1,column2,column3) 的3列联合索引，只要我们在查询中单独用到了第一列column1，或者column1和column2以及column1，column2，column3都能让查询使用这个联合索引来加速查询。 例如以下的 sql 查询，只有前两个 sql 查询会使用到 index(column1,column2,column3) 的联合索引，虽然第三和第四个 sql 查询中用到了索引中包含的列，但是不是索引中的最左前缀，所以无法使用该索引来完成查找。 12345select * from table_name where column1 = 'value'select * from table_name where column1 = 'value' and column2 = 'value'select * from table_name where column2 = 'value'select * from table_name where column2 = 'value' and column3 = 'value' 并且在联合索引中，对于第二列或之后的列，可以进行排序，例如对于index(name,age) 这个联合索引，我们可以获取重名的用户，并且按照年龄排序，这时使用联合索引就可以直接获取到已经排序过的数据，因为其本身在叶子节点中就已经排序了，例如下面这个 sql 查询： 1select * from user where name = 'zhangsan' order by age 覆盖索引如果查询中仅需要获得在索引中的列，那么可以直接从索引中获得数据，而不用再去查找数据行。 例如以下 sql 查询： 1select name from user where name LIKE 'zha%' 在这个 sql 查询语句返回的结果中，可以不用去获取数据行的内容，因为在 name 列的辅助索引中已经包含了该列的值，则可以从该辅助索引中直接返回所匹配的关键字即可，不需要在根据主键去聚簇索引中获取数据行，对于联合索引来讲，也是一样的效果。 查询执行计划MySQL中的 explain命令可以查看sql语句的执行计划，而通过执行计划我们可以了解到这条sql的查询方式、索引的使用情况、需要扫描的数据量、是否需要临时表及排序等操作信息。 我们需要分析执行计划，来进行有必要的优化，在sql语句前加上explain即可查看该sql语句的执行计划。 输出格式以explain select * from db where user = &#39;test&#39;查询为例，结果如下： 各列含义如下： 列名 含义 id 查询标识符 select_type 查询类型 table 输出行的表 partitions 匹配的分区 type 连接类型 possible_keys 可以选择的索引，但实际选择的索引由key字段决定 key 实际选择的索引 key_len 索引使用的字节数 ref 索引使用的列或常量 rows 预计需要检查的行数 filtered 按条件过滤的数据百分比 Extra 额外信息 查询类型下表显示了所有查询类型： 查询类型 含义 SIMPLE 简单的select查询，查询中不包含union或子查询 PRIMARY 查询中包含子查询，表示这是最外层查询 UNION union的第二个或之后的查询被标记为UNION DEPENDENT UNION 依赖外部查询的union UNION RESULT union的结果。 SUBQUERY 子查询 DEPENDENT SUBQUERY 依赖外部查询的子查询 DERIVED 用于from的子查询 DEPENDENT DERIVED 依赖外部查询的用于from的子查询 连接类型连接类型type介绍了如何连接表，以下列表从最佳类型到最差类型列出了所有的连接类型： system 表中只有一条数据，这是连接类型 const 的一个特例。 const 表示通过主键或唯一索引查询，最多只返回一行数据。因为只有一行数据，如果在where列表中，mysql能将该查询转换为一个常量，const 查询速度非常快, 因为它只需要读取一次。 eq_ref 对于每个来自于前面的表的结果，都只能从该表中匹配一行数据，连接的字段为主键或唯一索引。 在以下官方文档的示例中，可以使用eq_ref连接来处理ref_table表 ： 123456select * from ref_table,other_table where ref_table.key_column=other_table.column;select * from ref_table,other_table where ref_table.key_column_part1=other_table.column and ref_table.key_column_part2=1; ref_table表中的key_column列添加了唯一索引。 ref 对于每个来自于前面的表的结果，可以从该表中根据索引匹配几行数据，连接的字段具有非唯一索引或者使用了最左前缀规则的查询。 在以下官方文档的示例中，可以使用ref连接来处理ref_table表 ： 12345678select * from ref_table where key_column=expr;select * from ref_table,other_table where ref_table.key_column=other_table.column;select * from ref_table,other_table where ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; ref_table表中的key_column列添加了非唯一索引或使用了最左前缀的规则进行查询。 ref_or_null 该连接类型与ref类型相同，但是对包含NULL值的行进行额外搜索。 在以下官方文档的示例中，可以使用ref_or_null连接来处理ref_table表 ： 12select * from ref_table where key_column=expr or key_column is null; index_merge 该连接类型表示使用了索引合并优化方法。在这种情况下，key输出行中的列包含使用的索引列表，并且key_len包含所用索引的最长关键部分的列表。 unique_subquery 在以下官方文档的示例中，该类型替换了子查询的eq_ref类型 1value in (select primary_key from single_table where some_expr) primary_key列必须是主键或唯一索引。 index_subquery 该连接类型与unique_subquery类型相似，但它适用于子查询的查询结果列为非唯一索引的时候。 range 只检索给定范围的行，使用一个索引来选择行。 在以下官方文档的示例中，可以使用range连接： 1234567891011select * from tbl_name where key_column = 10;select * from tbl_name where key_column between 10 and 20;select * from tbl_name where key_column IN (10,20,30);select * from tbl_name where key_part1 = 10 and key_part2 in (10,20,30); index 该联接类型与ALL相同，只是索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 ALL 对于每个表进行全表扫描，可以添加索引来避免这个连接类型。 额外信息Extra 字段中会显示执行计划中的额外信息。以下列表说明了此列中可能出现的值： Distinct MySQL正在寻找不重复的匹配值，因此它在找到第一个匹配行后停止搜索更多的匹配行。 Not exists MySQL对left join查询进行优化，发现1个匹配left join条件的行后，不再检查更多的行。 Range checked for each record (index map: N) MySQL没有发现较好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对于上表中的每个行组合，检查是否可以使用range或 index_merge连接类型来检索行。 这虽然不是很快，但比执行没有索引的连接更快。、 索引从1开始编号，顺序与表中show index显示的顺序相同。索引映射值 N指示哪些索引是候选。例如，值0x19（二进制11001）表示将考虑索引1,4和5。 Using filesort 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果。 Using index 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 使用覆盖索引。 Using index condition 表示此查询用到了索引，但是需要查询表数据。 Using index for group-by 类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。 Using temporary MySQL需要创建一个临时表来容纳结果。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jinjinz.top/tags/MySQL/"}]}]